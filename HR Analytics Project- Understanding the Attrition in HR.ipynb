{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9758c698",
   "metadata": {},
   "source": [
    "# HR Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f40f8c",
   "metadata": {},
   "source": [
    "This repo contains the HR Analytics project as part of my data science portfolio. The objective is to predict employee attrition using a HR dataset from IBM Watson Analytics Sample Data - [HR Employee Attrition & Performance](https://www.ibm.com/communities/analytics/watson-analytics-blog/hr-employee-attrition/) which contains employee data for 1,470 employees with various information about the employees."
   ]
  },
  {
   "cell_type": "raw",
   "id": "c4c7989a",
   "metadata": {},
   "source": [
    ".  Problem Statement\n",
    ".  Dataset\n",
    ".  Exploratory Data Analysis\n",
    ".  Pre-processing Pipeline\n",
    ".  Building Machine Learning Models\n",
    ".  Discussion and Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b71d58e",
   "metadata": {},
   "source": [
    "# Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ae2051",
   "metadata": {},
   "source": [
    "Although some staff turnover is inevitable in any company, a high attrition rate is costly. Employee attrition is the overall turnover within a company as existing employees leave and new ones are hired. The attrition rate is usually calculated as the percentage of employees leaving the company over a specified period of time. Recruitment, hiring and training all involve financial costs and a new employee may not be immediately productive in terms of creating profit. The amount of time spent to interview and find a replacement, and the loss of productivity for several months while the new employee gets accustomed to the new role, are indirect costs to the company. These costs can significantly increase if executive-level or highest-paid employees are to be replaced. As such, the costs of replacing employees for most companies are often very significant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f1fbe9",
   "metadata": {},
   "source": [
    "An unusually high employee attrition rate is also considered indicative of problems within the company. Uncompetitive pay scales, micromanagement, ineffective human resource management (HRM) practices and unreasonable expectations can all lead to unacceptable levels of staff turnover. Understanding why and when employees are most likely to leave can lead to actions to improve employee retention as well as possibly planning new hiring in advance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a0b870",
   "metadata": {},
   "source": [
    "In this project, I will attempt to answer the following questions:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2be0908b",
   "metadata": {},
   "source": [
    ".  What is the probability of an employee leaving the company?\n",
    ".  What are the key drivers of an employee leaving the company?\n",
    ".  What are the recommendations or strategies that can be adopted to improve employee retention?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d318e2a",
   "metadata": {},
   "source": [
    "This is a standard supervised classification problem where the target or label is a binary variable, 0 (active employee), 1 (ex-employee). The objective is to predict employee attrition based on various information about the employee. I will also attempt to generate the probability of an employee leaving the company as our target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec910efd",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d0e173",
   "metadata": {},
   "source": [
    "The dataset used in this project is IBM Watson Analytics Sample Data - HR Employee Attrition & Performance. The dataset contains 1,470 rows corresponding to 1,470 employees with their various information. It is also available directly within Watson Analytics as Employee Performance. As mentioned on IBM website, the purpose of the dataset is to"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440401e2",
   "metadata": {},
   "source": [
    "Uncover the factors that lead to employee attrition and explore important questions such as ‘show me a breakdown of distance from home by job role and attrition’ or ‘compare average monthly income by education and attrition’. This is a fictional data set created by IBM data scientists."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ab2eaa",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222957d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742f38bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset\n",
    "df_raw = pd.read_excel(\"WA_Fn-UseC_-HR-Employee-Attrition.xlsx\", sheet_name=0)\n",
    "\n",
    "# make a copy of the original source file\n",
    "df = df_raw.copy()\n",
    "\n",
    "print(\"Size of dataset is: {}\".format(df.shape))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a2c2fb",
   "metadata": {},
   "source": [
    "Size of dataset is: (1470, 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d73e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    Age  Attrition  BusinessTravel     DailyRate  m Department            DistanceFromHome   Education   EducationField   EmployeeCount  EmployeeNumber  ...    RelationshipSatisfaction   StandardHours   StockOptionLevel  TotalWorkingYears  TrainingTimesLastYear  WorkLifeBalance  YearsAtCompany  YearsInCurrentRole  YearsSinceLastPromotion  YearsWithCurrManager\n",
    "0   41   Yes        Travel_Rarely      1102       Sales                   1                  2           Life Sciences    1              1               ...    1                          80              0                 8                  0                      1                6               4                   0                        5\n",
    "1   49   No         Travel_Frequently  279        Research & Development  8                  1           Life Sciences    1              2               ...    4                          80              1                 10                 3                      3                10              7                   1                        7\n",
    "2   37   Yes        Travel_Rarely      1373       Research & Development  2                  2           Other            1              4               ...    2                          80              0                 7                  3                      3                0               0                   0                        0\n",
    "3   33   No         Travel_Frequently  1392       Research & Development  3                  4           Life Sciences    1              5               ...    3                          80              0                 8                  3                      3                8               7                   3                        0\n",
    "4   27   No         Travel_Rarely      591        Research & Development  2                  1           Medical          1              7               ...    4                          80              1                 6                  3                      3                2               2                   2                        2\n",
    "5 rows × 35 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f3a247",
   "metadata": {},
   "source": [
    "There are 35 columns and 1,470 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126a332a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "raw",
   "id": "69fc076f",
   "metadata": {},
   "source": [
    "Index(['Age', 'Attrition', 'BusinessTravel', 'DailyRate', 'Department',\n",
    "       'DistanceFromHome', 'Education', 'EducationField', 'EmployeeCount',\n",
    "       'EmployeeNumber', 'EnvironmentSatisfaction', 'Gender', 'HourlyRate',\n",
    "       'JobInvolvement', 'JobLevel', 'JobRole', 'JobSatisfaction',\n",
    "       'MaritalStatus', 'MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked',\n",
    "       'Over18', 'OverTime', 'PercentSalaryHike', 'PerformanceRating',\n",
    "       'RelationshipSatisfaction', 'StandardHours', 'StockOptionLevel',\n",
    "       'TotalWorkingYears', 'TrainingTimesLastYear', 'WorkLifeBalance',\n",
    "       'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion',\n",
    "       'YearsWithCurrManager'],\n",
    "      dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72c1d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns datatypes\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53897cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 1470 entries, 0 to 1469\n",
    "Data columns (total 35 columns):\n",
    "Age                         1470 non-null int64\n",
    "Attrition                   1470 non-null object\n",
    "BusinessTravel              1470 non-null object\n",
    "DailyRate                   1470 non-null int64\n",
    "Department                  1470 non-null object\n",
    "DistanceFromHome            1470 non-null int64\n",
    "Education                   1470 non-null int64\n",
    "EducationField              1470 non-null object\n",
    "EmployeeCount               1470 non-null int64\n",
    "EmployeeNumber              1470 non-null int64\n",
    "EnvironmentSatisfaction     1470 non-null int64\n",
    "Gender                      1470 non-null object\n",
    "HourlyRate                  1470 non-null int64\n",
    "JobInvolvement              1470 non-null int64\n",
    "JobLevel                    1470 non-null int64\n",
    "JobRole                     1470 non-null object\n",
    "JobSatisfaction             1470 non-null int64\n",
    "MaritalStatus               1470 non-null object\n",
    "MonthlyIncome               1470 non-null int64\n",
    "MonthlyRate                 1470 non-null int64\n",
    "NumCompaniesWorked          1470 non-null int64\n",
    "Over18                      1470 non-null object\n",
    "OverTime                    1470 non-null object\n",
    "PercentSalaryHike           1470 non-null int64\n",
    "PerformanceRating           1470 non-null int64\n",
    "RelationshipSatisfaction    1470 non-null int64\n",
    "StandardHours               1470 non-null int64\n",
    "StockOptionLevel            1470 non-null int64\n",
    "TotalWorkingYears           1470 non-null int64\n",
    "TrainingTimesLastYear       1470 non-null int64\n",
    "WorkLifeBalance             1470 non-null int64\n",
    "YearsAtCompany              1470 non-null int64\n",
    "YearsInCurrentRole          1470 non-null int64\n",
    "YearsSinceLastPromotion     1470 non-null int64\n",
    "YearsWithCurrManager        1470 non-null int64\n",
    "dtypes: int64(26), object(9)\n",
    "memory usage: 402.0+ KB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04de60db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby column data types\n",
    "df.columns.groupby(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedc563a",
   "metadata": {},
   "outputs": [],
   "source": [
    "{dtype('int64'): Index(['Age', 'DailyRate', 'DistanceFromHome', 'Education', 'EmployeeCount',\n",
    "        'EmployeeNumber', 'EnvironmentSatisfaction', 'HourlyRate',\n",
    "        'JobInvolvement', 'JobLevel', 'JobSatisfaction', 'MonthlyIncome',\n",
    "        'MonthlyRate', 'NumCompaniesWorked', 'PercentSalaryHike',\n",
    "        'PerformanceRating', 'RelationshipSatisfaction', 'StandardHours',\n",
    "        'StockOptionLevel', 'TotalWorkingYears', 'TrainingTimesLastYear',\n",
    "        'WorkLifeBalance', 'YearsAtCompany', 'YearsInCurrentRole',\n",
    "        'YearsSinceLastPromotion', 'YearsWithCurrManager'],\n",
    "       dtype='object'),\n",
    " dtype('O'): Index(['Attrition', 'BusinessTravel', 'Department', 'EducationField', 'Gender',\n",
    "        'JobRole', 'MaritalStatus', 'Over18', 'OverTime'],\n",
    "       dtype='object')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24342f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of columns\n",
    "print(\"No of columns for {} is {}.\".format(list(df.columns.groupby(df.dtypes).keys())[0], len(df.columns.groupby(df.dtypes)[list(df.columns.groupby(df.dtypes).keys())[0]])))\n",
    "print(\"No of columns for {} is {}.\".format(list(df.columns.groupby(df.dtypes).keys())[1], len(df.columns.groupby(df.dtypes)[list(df.columns.groupby(df.dtypes).keys())[1]])))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6c21dbf8",
   "metadata": {},
   "source": [
    ".  No of columns for int64 is 26.\n",
    ".  No of columns for object is 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa979f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9888705",
   "metadata": {},
   "outputs": [],
   "source": [
    "Age                         0\n",
    "Attrition                   0\n",
    "BusinessTravel              0\n",
    "DailyRate                   0\n",
    "Department                  0\n",
    "DistanceFromHome            0\n",
    "Education                   0\n",
    "EducationField              0\n",
    "EmployeeCount               0\n",
    "EmployeeNumber              0\n",
    "EnvironmentSatisfaction     0\n",
    "Gender                      0\n",
    "HourlyRate                  0\n",
    "JobInvolvement              0\n",
    "JobLevel                    0\n",
    "JobRole                     0\n",
    "JobSatisfaction             0\n",
    "MaritalStatus               0\n",
    "MonthlyIncome               0\n",
    "MonthlyRate                 0\n",
    "NumCompaniesWorked          0\n",
    "Over18                      0\n",
    "OverTime                    0\n",
    "PercentSalaryHike           0\n",
    "PerformanceRating           0\n",
    "RelationshipSatisfaction    0\n",
    "StandardHours               0\n",
    "StockOptionLevel            0\n",
    "TotalWorkingYears           0\n",
    "TrainingTimesLastYear       0\n",
    "WorkLifeBalance             0\n",
    "YearsAtCompany              0\n",
    "YearsInCurrentRole          0\n",
    "YearsSinceLastPromotion     0\n",
    "YearsWithCurrManager        0\n",
    "dtype: int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bacb652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3084e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "      Age           DailyRate     DistanceFromHome  Education    EmployeeCount  EmployeeNumber  EnvironmentSatisfaction  HourlyRate    JobInvolvement JobLevel     ...    RelationshipSatisfaction  StandardHours  StockOptionLevel   TotalWorkingYears  TrainingTimesLastYear  WorkLifeBalance  YearsAtCompany   YearsInCurrentRole  YearsSinceLastPromotion  YearsWithCurrManager\n",
    "count 1470.000000   1470.000000   1470.000000       1470.000000  1470.0         1470.000000     1470.000000              1470.000000   1470.000000    1470.000000  ...    1470.000000               1470.0         1470.000000        1470.000000        1470.000000            1470.000000      1470.000000      1470.000000         1470.000000              1470.000000\n",
    "mean  36.923810     802.485714    9.192517          2.912925     1.0            1024.865306     2.721769                 65.891156     2.729932       2.063946     ...    2.712245                  80.0           0.793878           11.279592          2.799320               2.761224         7.008163         4.229252            2.187755                 4.123129\n",
    "std   9.135373      403.509100    8.106864          1.024165     0.0            602.024335      1.093082                 20.329428     0.711561       1.106940     ...    1.081209                  0.0            0.852077           7.780782           1.289271               0.706476         6.126525         3.623137            3.222430                 3.568136\n",
    "min   18.000000     102.000000    1.000000          1.000000     1.0            1.000000        1.000000                 30.000000     1.000000       1.000000     ...    1.000000                  80.0           0.000000           0.000000           0.000000               1.000000         0.000000         0.000000            0.000000                 0.000000\n",
    "25%   30.000000     465.000000    2.000000          2.000000     1.0            491.250000      2.000000                 48.000000     2.000000       1.000000     ...    2.000000                  80.0           0.000000           6.000000           2.000000               2.000000         3.000000         2.000000            0.000000                 2.000000\n",
    "50%   36.000000     802.000000    7.000000          3.000000     1.0            1020.500000     3.000000                 66.000000     3.000000       2.000000     ...    3.000000                  80.0           1.000000           10.000000          3.000000               3.000000         5.000000         3.000000            1.000000                 3.000000\n",
    "75%   43.000000     1157.000000   14.000000         4.000000     1.0            1555.750000     4.000000                 83.750000     3.000000       3.000000     ...    4.000000                  80.0           1.000000           15.000000          3.000000               3.000000         9.000000         7.000000            3.000000                 7.000000\n",
    "max   60.000000     1499.000000   29.000000         5.000000     1.0            2068.000000     4.000000                 100.00000     4.000000       5.000000     ...    4.000000                  80.0           3.000000           40.000000          6.000000               4.000000         40.000000        18.000000           15.000000                17.000000\n",
    "8 rows × 26 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53032f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary statistics\n",
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19cc2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "        Age\tAttrition   BusinessTravel  DailyRate  Department               DistanceFromHome  Education     EducationField   EmployeeCount   EmployeeNumber   ...   RelationshipSatisfaction  StandardHours  StockOptionLevel  TotalWorkingYears   TrainingTimesLastYear  WorkLifeBalance  YearsAtCompany  YearsInCurrentRole  YearsSinceLastPromotion  YearsWithCurrManager\n",
    "count   1470.000000     1470            1470       1470.000000              1470              1470.000000   1470.000000      1470            1470.000000      ...   1470.000000               1470.0         1470.000000       1470.000000         1470.000000            1470.000000      1470.000000     1470.000000         1470.000000              1470.000000\n",
    "unique  NaN             2               3          NaN                      3                 NaN           NaN              6               NaN              ...   NaN                       NaN            NaN               NaN                 NaN                    NaN              NaN             NaN                 NaN                      NaN\n",
    "top\tNaN No              Travel_Rarely   NaN        Research & Development   NaN               NaN           Life Sciences    NaN             NaN              ...   NaN                       NaN            NaN               NaN                 NaN                    NaN              NaN             NaN                 NaN                      NaN\n",
    "freq    NaN             1233            1043       NaN                      961               NaN           NaN              606             NaN              ...   NaN                       NaN            NaN               NaN                 NaN                    NaN              NaN             NaN                 NaN                      NaN\n",
    "mean    36.923810       NaN             NaN        802.485714               NaN               9.192517      2.912925         NaN             1.0              ...   2.712245                  80.0           0.793878          11.279592           2.799320               2.761224         7.008163        4.229252            2.187755                 4.123129\n",
    "std     9.135373        NaN             NaN        403.509100               NaN               8.106864      1.024165         NaN             0.0              ...   1.081209                  0.0            0.852077          7.780782            1.289271               0.706476         6.126525        3.623137            3.222430                 3.568136\n",
    "min     18.000000       NaN             NaN        102.000000               NaN               1.000000      1.000000         NaN             1.0              ...   1.000000                  80.0           0.000000          0.000000            0.000000               1.000000         0.000000        0.000000            0.000000                 0.000000\n",
    "25%     30.000000       NaN             NaN        465.000000               NaN               2.000000      2.000000         NaN             1.0              ...   2.000000                  80.0           0.000000          6.000000            2.000000               2.000000         3.000000        2.000000            0.000000                 2.000000\n",
    "50%     36.000000       NaN             NaN        802.000000               NaN               7.000000      3.000000         NaN             1.0              ...   3.000000                  80.0           1.000000          10.000000           3.000000               3.000000         5.000000        3.000000            1.000000                 3.000000\n",
    "75%     43.000000       NaN             NaN        1157.000000              NaN               14.000000     4.000000         NaN             1.0              ...   4.000000                  80.0           1.000000          15.000000           3.000000               3.000000         9.000000        7.000000            3.000000                 7.000000\n",
    "max     60.000000       NaN             NaN        1499.000000              NaN               29.000000     5.000000         NaN             1.0              ...   4.000000                  80.0           3.000000          40.000000           6.000000               4.000000         40.000000       18.000000           15.000000                17.000000\n",
    "11 rows × 35 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb778df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histogram for numeric columns\n",
    "df.hist(figsize=(20,20))\n",
    "# plt.savefig(\"histograms.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c64dda5",
   "metadata": {},
   "source": [
    "Your code snippet aims to plot histograms for numeric columns in your DataFrame. It's a good way to visualize the distribution of each numerical variable. Here's how you can plot histograms for numeric columns using Matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6cae40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot histograms for numeric columns\n",
    "df.hist(figsize=(20, 20))\n",
    "plt.tight_layout()  # Adjust layout to prevent overlapping\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4391e733",
   "metadata": {},
   "source": [
    "This will generate histograms for each numeric column in your DataFrame. Adjust the figsize parameter to change the size of the plot according to your preference. Uncomment the plt.savefig line if you want to save the plot as an image file. Make sure to provide the correct filename and path."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548ecf69",
   "metadata": {},
   "source": [
    "# Features / Input Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2384f61",
   "metadata": {},
   "source": [
    "# Age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce03919",
   "metadata": {},
   "source": [
    "Age of employees is from 18 to 60 years old. The average age of ex-employees at 33.6 years old and 37.6 years old for current employees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24128110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age\n",
    "print(\"Age of employees is from {} to {} years old.\".format(df['Age'].min(), df['Age'].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d1eb3d",
   "metadata": {},
   "source": [
    "Age of employees is from 18 to 60 years old."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55832da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex-Employees\n",
    "print(\"Ex-Employees:\")\n",
    "print(\"Average Age of Ex-Employees = {:1.1f}\".format(np.mean(df.loc[df['Attrition'] == 'Yes', 'Age'])))\n",
    "print(\"Standard Deviation = {:1.1f}\".format(np.std(df.loc[df['Attrition'] == 'Yes', 'Age'])))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bdd99d3f",
   "metadata": {},
   "source": [
    "Ex-Employees:\n",
    "Average Age of Ex-Employees = 33.6\n",
    "Standard Deviation = 9.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436dd552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Active Employees\n",
    "print(\"Active Employees:\")\n",
    "print(\"Average Age of Active Employees = {:1.1f}\".format(np.mean(df.loc[df['Attrition'] == 'No', 'Age'])))\n",
    "print(\"Standard Deviation = {:1.1f}\".format(np.std(df.loc[df['Attrition'] == 'No', 'Age'])))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c670f0cc",
   "metadata": {},
   "source": [
    "Active Employees:\n",
    "Average Age of Active Employees = 37.6\n",
    "Standard Deviation = 8.9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e53248",
   "metadata": {},
   "source": [
    "We can create a kernel density estimation (KDE) plot colored by the value of the target. A kernel density estimation (KDE) is a non-parametric way to estimate the probability density function of a random variable. Density plots are representations of the underlying distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17eb0a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel density estimation (KDE) plot \n",
    "\n",
    "plt.subplots(figsize=(12,4))\n",
    "\n",
    "target_0 = df.loc[df[\"Attrition\"] == \"No\"]\n",
    "target_1 = df.loc[df[\"Attrition\"] == \"Yes\"]\n",
    "\n",
    "sns.distplot(target_0[[\"Age\"]], hist=False, label=\"Active Employees\")\n",
    "sns.distplot(target_1[[\"Age\"]], hist=False, label=\"Ex-Exployees\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Age\", fontsize=12)\n",
    "plt.ylabel(\"Density\", fontsize=12)\n",
    "plt.title(\"Age Distribution by Attrition Status\", x=0.5, y=1.05, ha=\"center\", fontsize=14)\n",
    "\n",
    "# plt.savefig(\"age_kde.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146c0a58",
   "metadata": {},
   "source": [
    "# Aag Distribution by Attrition Status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e22c419",
   "metadata": {},
   "source": [
    "To create a distribution plot of Age by Attrition Status, you can use Seaborn's histplot function. Here's how you can do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39be71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create the distribution plot\n",
    "sns.histplot(data=df, x='Age', hue='Attrition', kde=True, bins=30, palette='muted')\n",
    "\n",
    "# Set the title and labels\n",
    "plt.title('Age Distribution by Attrition Status')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4d4b28",
   "metadata": {},
   "source": [
    "This will generate a histogram of age distribution, with Attrition status differentiated by color. Adjust the bins parameter to change the number of bins in the histogram. You can also modify the palette parameter to change the color scheme.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc0cf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel density estimation (KDE) plot \n",
    "\n",
    "plt.subplots(figsize=(12,4))\n",
    "\n",
    "target_0 = df.loc[df[\"Attrition\"] == \"No\"]\n",
    "target_1 = df.loc[df[\"Attrition\"] == \"Yes\"]\n",
    "\n",
    "sns.distplot(target_0[[\"Age\"]], hist=False, label=\"Active Employees\")\n",
    "sns.distplot(target_1[[\"Age\"]], hist=False, label=\"Ex-Exployees\")\n",
    "plt.legend()\n",
    "plt.xlim(df[\"Age\"].min(), df[\"Age\"].max())\n",
    "plt.xlabel(\"Age\", fontsize=12)\n",
    "plt.ylabel(\"Density\", fontsize=12)\n",
    "plt.title(\"Age Distribution in Percent by Attrition Status\", x=0.5, y=1.05, ha=\"center\", fontsize=14)\n",
    "\n",
    "# plt.savefig(\"age_kde.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce71856d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histogram\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "fig.set_size_inches(12,4)\n",
    "\n",
    "target_0[['Age']].hist(bins=20, ax=axes[0])\n",
    "axes[0].set_title('Active Employees')\n",
    "\n",
    "target_1[['Age']].hist(bins=20, ax=axes[1])\n",
    "axes[1].set_title('Ex-Employees')\n",
    "\n",
    "fig.text(0.5, 0.01, 'Age', ha='center')\n",
    "fig.text(0.07, 0.5, 'No of Employee', va='center', rotation='vertical')\n",
    "\n",
    "# plt.savefig(\"age_hist.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b6c6bc",
   "metadata": {},
   "source": [
    "# Gender"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f82988f",
   "metadata": {},
   "source": [
    "Gender distribution shows that the dataset features a higher relative proportion of male ex-employees than female ex-employees, with normalised gender distribution of ex-employees in the dataset at 17% for Males and 15% for Females."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fd65ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender of employees\n",
    "df['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e019f21d",
   "metadata": {},
   "source": [
    "Male      882\n",
    "Female    588\n",
    "Name: Gender, dtype: int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3460eacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender of employees\n",
    "df['Gender'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ed3e1d47",
   "metadata": {},
   "source": [
    "Male      0.6\n",
    "Female    0.4\n",
    "Name: Gender, dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96121b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(16,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "g2 = df.loc[df['Attrition'] == 'Yes', 'Gender'].value_counts().plot.bar(title= 'Ex-Employees', color=\"#1f77b4\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim(0,170)\n",
    "for p in g2.patches:\n",
    "    height = p.get_height()\n",
    "    g2.text(p.get_x()+p.get_width()/2., height+3, \"{:1.0f}\".format(height), ha=\"center\", fontsize=14) \n",
    "    \n",
    "plt.subplot(122)\n",
    "g2 = df.loc[df['Attrition'] == 'No', 'Gender'].value_counts().plot.bar(title= 'Active Employees', color=\"#1f77b4\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim(0,850)\n",
    "for p in g2.patches:\n",
    "    height = p.get_height()\n",
    "    g2.text(p.get_x()+p.get_width()/2., height+15, \"{:1.0f}\".format(height), ha=\"center\", fontsize=14) \n",
    "    \n",
    "fig.text(0.5, 0.01, 'Gender', ha='center')\n",
    "fig.text(0.07, 0.5, 'No of Employee', va='center', rotation='vertical')\n",
    "\n",
    "# plt.savefig(\"gender_hist_1.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db4a66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(16,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "g1 = df.loc[df['Attrition'] == 'Yes', 'Gender'].value_counts(normalize=True).plot.bar(title= 'Ex-Employees', color=\"#1f77b4\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim(0,1)\n",
    "for p in g1.patches:\n",
    "    height = p.get_height()\n",
    "    g1.text(p.get_x()+p.get_width()/2., height+0.02, \"{:1.2f}\".format(height), ha=\"center\", fontsize=14) \n",
    "    \n",
    "plt.subplot(122)\n",
    "g2 = df.loc[df['Attrition'] == 'No', 'Gender'].value_counts(normalize=True).plot.bar(title= 'Active Employees', color=\"#1f77b4\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim(0,1)\n",
    "for p in g2.patches:\n",
    "    height = p.get_height()\n",
    "    g2.text(p.get_x()+p.get_width()/2., height+0.02, \"{:1.2f}\".format(height), ha=\"center\", fontsize=14) \n",
    "    \n",
    "fig.text(0.5, 0.01, 'Gender', ha='center')\n",
    "fig.text(0.07, 0.5, '% of Employee', va='center', rotation='vertical')\n",
    "\n",
    "# plt.savefig(\"gender_hist_2.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4122e93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(16,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "g1 = df.loc[df['Gender'] == 'Male', 'Attrition'].value_counts().reindex([\"Yes\", \"No\"]).plot.bar(title= 'Male', color=\"#1f77b4\")\n",
    "g1.set_xticklabels([\"Ex-Employee\", \"Active Employee\"])\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim(0,850)\n",
    "for p in g1.patches:\n",
    "    height = p.get_height()\n",
    "    g1.text(p.get_x()+p.get_width()/2., height+20, \"{:1.0f}\".format(height), ha=\"center\", fontsize=14) \n",
    "    \n",
    "plt.subplot(122)\n",
    "g2 = df.loc[df['Gender'] == 'Female', 'Attrition'].value_counts().reindex([\"Yes\", \"No\"]).plot.bar(title= 'Female', color=\"#1f77b4\")\n",
    "g2.set_xticklabels([\"Ex-Employee\", \"Active Employee\"])\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim(0,600)\n",
    "for p in g2.patches:\n",
    "    height = p.get_height()\n",
    "    g2.text(p.get_x()+p.get_width()/2., height+10, \"{:1.0f}\".format(height), ha=\"center\", fontsize=14) \n",
    "    \n",
    "fig.text(0.5, 0.01, 'Attrition', ha='center')\n",
    "fig.text(0.07, 0.5, 'No of Employee', va='center', rotation='vertical')\n",
    "\n",
    "# plt.savefig(\"gender_hist_3.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3415bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(16,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "g1 = df.loc[df['Gender'] == 'Male', 'Attrition'].value_counts(normalize=True).reindex([\"Yes\", \"No\"]).plot.bar(title= 'Male', color=\"#1f77b4\")\n",
    "g1.set_xticklabels([\"Ex-Employee\", \"Active Employee\"])\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim(0,1)\n",
    "for p in g1.patches:\n",
    "    height = p.get_height()\n",
    "    g1.text(p.get_x()+p.get_width()/2., height+0.015, \"{:1.2f}\".format(height), ha=\"center\", fontsize=14) \n",
    "    \n",
    "plt.subplot(122)\n",
    "g2 = df.loc[df['Gender'] == 'Female', 'Attrition'].value_counts(normalize=True).reindex([\"Yes\", \"No\"]).plot.bar(title= 'Female', color=\"#1f77b4\")\n",
    "g2.set_xticklabels([\"Ex-Employee\", \"Active Employee\"])\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim(0,1)\n",
    "for p in g2.patches:\n",
    "    height = p.get_height()\n",
    "    g2.text(p.get_x()+p.get_width()/2., height+0.02, \"{:1.2f}\".format(height), ha=\"center\", fontsize=14) \n",
    "    \n",
    "fig.text(0.5, 0.01, 'Attrition', ha='center')\n",
    "fig.text(0.07, 0.5, '% of Employee', va='center', rotation='vertical')\n",
    "\n",
    "# plt.savefig(\"gender_hist_4.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fac8259",
   "metadata": {},
   "source": [
    "# Marital Status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d8bd22",
   "metadata": {},
   "source": [
    "The dataset features three marital status: Married (673 employees), Single (470 employees), Divorced (327 employees). Single employees show the largest proportion of leavers at 25%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e97966c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# marital Status of employees\n",
    "df['MaritalStatus'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51e900e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Married     673\n",
    "Single      470\n",
    "Divorced    327\n",
    "Name: MaritalStatus, dtype: int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247f67d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# marital Status of employees\n",
    "df['MaritalStatus'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68db75e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Married     0.457823\n",
    "Single      0.319728\n",
    "Divorced    0.222449\n",
    "Name: MaritalStatus, dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfea10e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(16,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "g2 = df.loc[df['Attrition'] == 'Yes', 'MaritalStatus'].value_counts().plot.bar(title= 'Ex-Employees', color=\"#1f77b4\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim(0,150)\n",
    "for p in g2.patches:\n",
    "    height = p.get_height()\n",
    "    g2.text(p.get_x()+p.get_width()/2., height+3, \"{:1.0f}\".format(height), ha=\"center\", fontsize=14) \n",
    "    \n",
    "plt.subplot(122)\n",
    "g2 = df.loc[df['Attrition'] == 'No', 'MaritalStatus'].value_counts().reindex([\"Single\", \"Married\",\"Divorced\"]).plot.bar(title= 'Active Employees', color=\"#1f77b4\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim(0,700)\n",
    "for p in g2.patches:\n",
    "    height = p.get_height()\n",
    "    g2.text(p.get_x()+p.get_width()/2., height+12, \"{:1.0f}\".format(height), ha=\"center\", fontsize=14) \n",
    "\n",
    "# set title and axis labels\n",
    "plt.suptitle('Attrition by Marital Status', x=0.5, y=1.05, ha='center', fontsize=16)\n",
    "fig.text(0.5, 0.001, 'Marital Status', ha='center', fontsize=14)\n",
    "fig.text(0.07, 0.5, 'No of Employee', va='center', rotation='vertical', fontsize=14)\n",
    "\n",
    "# plt.savefig(\"marital_hist_1.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde82744",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(16,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "g1 = df.loc[df[\"Attrition\"] == \"Yes\", \"MaritalStatus\"].value_counts(normalize=True).plot.bar(title= \"Ex-Employees\", color=\"#1f77b4\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim(0,0.6)\n",
    "for p in g1.patches:\n",
    "    height = p.get_height()\n",
    "    g1.text(p.get_x()+p.get_width()/2., height+0.01, \"{:1.2f}\".format(height), ha=\"center\", fontsize=14) \n",
    "    \n",
    "plt.subplot(122)\n",
    "g2 = df.loc[df[\"Attrition\"] == \"No\", \"MaritalStatus\"].value_counts(normalize=True).reindex([\"Single\", \"Married\",\"Divorced\"]).plot.bar(title= \"Active Employees\", color=\"#1f77b4\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim(0,0.6)\n",
    "for p in g2.patches:\n",
    "    height = p.get_height()\n",
    "    g2.text(p.get_x()+p.get_width()/2., height+0.01, \"{:1.2f}\".format(height), ha=\"center\", fontsize=14) \n",
    "    \n",
    "# set title and axis labels\n",
    "plt.suptitle(\"Attrition by Marital Status\", x=0.5, y=1.05, ha=\"center\", fontsize=16)\n",
    "fig.text(0.5, 0.001, \"Marital Status\", ha=\"center\", fontsize=14)\n",
    "fig.text(0.07, 0.5, \"No of Employee\", va=\"center\", rotation=\"vertical\", fontsize=14)\n",
    "\n",
    "# plt.savefig(\"marital_hist_2.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43132133",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(16,4))\n",
    "\n",
    "plt.subplot(131)\n",
    "g1 = df.loc[df['MaritalStatus'] == 'Single', 'Attrition'].value_counts().sort_values(ascending=True).plot.bar(title= 'Single', color=\"#1f77b4\")\n",
    "g1.set_xticklabels([\"Ex-Employee\", \"Active Employee\"])\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim(0,700)\n",
    "for p in g1.patches:\n",
    "    height = p.get_height()\n",
    "    g1.text(p.get_x()+p.get_width()/2., height+10, \"{:1.0f}\".format(height), ha=\"center\", fontsize=14) \n",
    "    \n",
    "plt.subplot(132)\n",
    "g2 = df.loc[df['MaritalStatus'] == 'Married', 'Attrition'].value_counts().sort_values(ascending=True).plot.bar(title= 'Married', color=\"#1f77b4\")\n",
    "g2.set_xticklabels([\"Ex-Employee\", \"Active Employee\"])\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim(0,700)\n",
    "for p in g2.patches:\n",
    "    height = p.get_height()\n",
    "    g2.text(p.get_x()+p.get_width()/2., height+12, \"{:1.0f}\".format(height), ha=\"center\", fontsize=14) \n",
    "    \n",
    "plt.subplot(133)\n",
    "g3 = df.loc[df['MaritalStatus'] == 'Divorced', 'Attrition'].value_counts().sort_values(ascending=True).plot.bar(title= 'Divorced', color=\"#1f77b4\")\n",
    "g3.set_xticklabels([\"Ex-Employee\", \"Active Employee\"])\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim(0,700)\n",
    "for p in g3.patches:\n",
    "    height = p.get_height()\n",
    "    g3.text(p.get_x()+p.get_width()/2., height+10, \"{:1.0f}\".format(height), ha=\"center\", fontsize=14) \n",
    "    \n",
    "# set title and axis labels\n",
    "plt.suptitle(\"Marital Status by Attrition Status\", x=0.5, y=1.05, ha=\"center\", fontsize=16)\n",
    "fig.text(0.5, 0.001, \"Marital Status\", ha=\"center\", fontsize=14)\n",
    "fig.text(0.07, 0.5, \"No of Employee\", va=\"center\", rotation=\"vertical\", fontsize=14)\n",
    "\n",
    "# plt.savefig(\"marital_hist_3.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98666ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(16,4))\n",
    "\n",
    "plt.subplot(131)\n",
    "g1 = df.loc[df['MaritalStatus'] == 'Single', 'Attrition'].value_counts(normalize=True).sort_values(ascending=True).plot.bar(title= 'Single', color=\"#1f77b4\")\n",
    "g1.set_xticklabels([\"Ex-Employee\", \"Active Employee\"])\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim(0,1)\n",
    "for p in g1.patches:\n",
    "    height = p.get_height()\n",
    "    g1.text(p.get_x()+p.get_width()/2., height+0.02, \"{:1.2f}\".format(height), ha=\"center\", fontsize=14) \n",
    "    \n",
    "plt.subplot(132)\n",
    "g2 = df.loc[df['MaritalStatus'] == 'Married', 'Attrition'].value_counts(normalize=True).sort_values(ascending=True).plot.bar(title= 'Married', color=\"#1f77b4\")\n",
    "g2.set_xticklabels([\"Ex-Employee\", \"Active Employee\"])\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim(0,1)\n",
    "for p in g2.patches:\n",
    "    height = p.get_height()\n",
    "    g2.text(p.get_x()+p.get_width()/2., height+0.02, \"{:1.2f}\".format(height), ha=\"center\", fontsize=14) \n",
    "    \n",
    "plt.subplot(133)\n",
    "g3 = df.loc[df['MaritalStatus'] == 'Divorced', 'Attrition'].value_counts(normalize=True).sort_values(ascending=True).plot.bar(title= 'Divorced', color=\"#1f77b4\")\n",
    "g3.set_xticklabels([\"Ex-Employee\", \"Active Employee\"])\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim(0,1)\n",
    "for p in g3.patches:\n",
    "    height = p.get_height()\n",
    "    g3.text(p.get_x()+p.get_width()/2., height+0.01, \"{:1.2f}\".format(height), ha=\"center\", fontsize=14) \n",
    "    \n",
    "# set title and axis labels\n",
    "plt.suptitle(\"Marital Status by Attrition Status\", x=0.5, y=1.05, ha=\"center\", fontsize=16)\n",
    "fig.text(0.5, 0.001, \"Marital Status\", ha=\"center\", fontsize=14)\n",
    "fig.text(0.07, 0.5, \"No of Employee\", va=\"center\", rotation=\"vertical\", fontsize=14)\n",
    "\n",
    "# plt.savefig(\"marital_hist_4.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88df22a6",
   "metadata": {},
   "source": [
    "# Distance from Home"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44f7d91",
   "metadata": {},
   "source": [
    "Distance from home for employees to get to work varies from 1 to 29 miles. There is no discernable strong correlation between Distance from Home and Attrition Status as per the KDE plot below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cdd5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance from Home\n",
    "print(\"Distance from home for employees to get to work is from {} to {} miles.\".format(df['DistanceFromHome'].min(), df['DistanceFromHome'].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844af191",
   "metadata": {},
   "source": [
    "Distance from home for employees to get to work is from 1 to 29 miles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812f4571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex-Employees\n",
    "print(\"Ex-Employees:\")\n",
    "print(\"Average Distance From Home of Ex-Employees = {:1.2f} miles\".format(np.mean(df.loc[df['Attrition'] == 'Yes', 'DistanceFromHome'])))\n",
    "print(\"Standard Deviation = {:1.2f}\".format(np.std(df.loc[df['Attrition'] == 'Yes', 'DistanceFromHome'])))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c6a8c2a9",
   "metadata": {},
   "source": [
    "Ex-Employees:\n",
    "Average Distance From Home of Ex-Employees = 10.63 miles\n",
    "Standard Deviation = 8.43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3f32aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Active Employees\n",
    "print(\"Active Employees:\")\n",
    "print(\"Average Distance From Home of Active Employees = {:1.2f} miles\".format(np.mean(df.loc[df['Attrition'] == 'No', 'DistanceFromHome'])))\n",
    "print(\"Standard Deviation = {:1.2f}\".format(np.std(df.loc[df['Attrition'] == 'No', 'DistanceFromHome'])))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "55a0ade8",
   "metadata": {},
   "source": [
    "Active Employees:\n",
    "Average Distance From Home of Active Employees = 8.92 miles\n",
    "Standard Deviation = 8.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9168f557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel density estimation (KDE) plot \n",
    "\n",
    "plt.subplots(figsize=(12,4))\n",
    "\n",
    "target_0 = df.loc[df[\"Attrition\"] == \"No\"]\n",
    "target_1 = df.loc[df[\"Attrition\"] == \"Yes\"]\n",
    "\n",
    "sns.distplot(target_0[[\"DistanceFromHome\"]], hist=False, label=\"Active Employees\")\n",
    "sns.distplot(target_1[[\"DistanceFromHome\"]], hist=False, label=\"Ex-Exployees\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Distance From Home\", fontsize=12)\n",
    "plt.ylabel(\"Density\", fontsize=12)\n",
    "plt.title(\"Distance From Home Distribution by Attrition Status\", fontsize=14)\n",
    "\n",
    "# plt.savefig(\"distance_kde.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031ab07b",
   "metadata": {},
   "source": [
    "# Distance From Home Distribution by Attrition Status "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae991779",
   "metadata": {},
   "source": [
    "To visualize the distribution of \"Distance From Home\" by \"Attrition Status,\" you can use Seaborn's histplot function again. Here's how you can create the chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfb56df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create the distribution plot\n",
    "sns.histplot(data=df, x='DistanceFromHome', hue='Attrition', kde=True, bins=30, palette='muted')\n",
    "\n",
    "# Set the title and labels\n",
    "plt.title('Distance From Home Distribution by Attrition Status')\n",
    "plt.xlabel('Distance From Home')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b259be",
   "metadata": {},
   "source": [
    "This code will generate a histogram showing the distribution of \"Distance From Home,\" with the Attrition status differentiated by color. Adjust the bins parameter to change the number of bins in the histogram, and modify the palette parameter to change the color scheme if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312d6f7a",
   "metadata": {},
   "source": [
    "You can get negative x-values ending up with some positive density from a kernel density estimate, simply because of the way KDEs work. Refer https://stats.stackexchange.com/questions/109549/negative-density-for-non-negative-variables and https://www.youtube.com/watch?v=R6_LR-f6Tt4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d3ff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel density estimation (KDE) plot \n",
    "\n",
    "plt.subplots(figsize=(12,4))\n",
    "\n",
    "target_0 = df.loc[df[\"Attrition\"] == \"No\"]\n",
    "target_1 = df.loc[df[\"Attrition\"] == \"Yes\"]\n",
    "\n",
    "sns.distplot(target_0[[\"DistanceFromHome\"]], hist=False, label=\"Active Employees\")\n",
    "sns.distplot(target_1[[\"DistanceFromHome\"]], hist=False, label=\"Ex-Exployees\")\n",
    "plt.legend()\n",
    "plt.xlim(df[\"DistanceFromHome\"].min(), df[\"DistanceFromHome\"].max())\n",
    "plt.xlabel(\"Distance From Home\", fontsize=12)\n",
    "plt.ylabel(\"Density\", fontsize=12)\n",
    "plt.title(\"Distance From Home Distribution by Attrition Status\", fontsize=14)\n",
    "\n",
    "# plt.savefig(\"distance_kde.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30cd132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histogram\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "fig.set_size_inches(12,4)\n",
    "\n",
    "target_0[['DistanceFromHome']].hist(bins=20, ax=axes[0])\n",
    "axes[0].set_title('Active Employees')\n",
    "\n",
    "target_1[['DistanceFromHome']].hist(bins=20, ax=axes[1])\n",
    "axes[1].set_title('Ex-Employees')\n",
    "\n",
    "fig.text(0.5, 0.01, 'DistanceFromHome', ha='center', fontsize=12)\n",
    "fig.text(0.07, 0.5, 'No of Employee', va='center', rotation='vertical', fontsize=12)\n",
    "\n",
    "# plt.savefig(\"distance_hist.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb2d531",
   "metadata": {},
   "source": [
    "# Department"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c6a659",
   "metadata": {},
   "source": [
    "The data features employee data from three departments: Research & Development, Sales, and Human Resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dafdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# departments\n",
    "df['Department'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2507fb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "Research & Development    961\n",
    "Sales                     446\n",
    "Human Resources            63\n",
    "Name: Department, dtype: int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da410e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# departments\n",
    "df['Department'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93f4625",
   "metadata": {},
   "outputs": [],
   "source": [
    "Research & Development    0.653741\n",
    "Sales                     0.303401\n",
    "Human Resources           0.042857\n",
    "Name: Department, dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baad62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(16,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "g2 = df.loc[df['Attrition'] == 'Yes', 'Department'].value_counts().plot.bar(title= 'Ex-Employees', color=\"#1f77b4\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim(0,160)\n",
    "for p in g2.patches:\n",
    "    height = p.get_height()\n",
    "    g2.text(p.get_x()+p.get_width()/2., height+3, \"{:1.0f}\".format(height), ha=\"center\", fontsize=14) \n",
    "    \n",
    "plt.subplot(122)\n",
    "g2 = df.loc[df['Attrition'] == 'No', 'Department'].value_counts().plot.bar(title= 'Active Employees', color=\"#1f77b4\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim(0,1000)\n",
    "for p in g2.patches:\n",
    "    height = p.get_height()\n",
    "    g2.text(p.get_x()+p.get_width()/2., height+12, \"{:1.0f}\".format(height), ha=\"center\", fontsize=14) \n",
    "\n",
    "# set title and axis labels\n",
    "plt.suptitle('Attrition Status by Department', fontsize=16)\n",
    "fig.text(0.5, 0.001, 'Marital Status', ha='center', fontsize=14)\n",
    "fig.text(0.07, 0.5, 'No of Employee', va='center', rotation='vertical', fontsize=14)\n",
    "\n",
    "# plt.savefig(\"dept_hist_1.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5f5fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(16,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "g1 = df.loc[df[\"Attrition\"] == \"Yes\", \"Department\"].value_counts(normalize=True).plot.bar(title= \"Ex-Employees\", color=\"#1f77b4\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim(0,1)\n",
    "for p in g1.patches:\n",
    "    height = p.get_height()\n",
    "    g1.text(p.get_x()+p.get_width()/2., height+0.01, \"{:1.2f}\".format(height), ha=\"center\", fontsize=14) \n",
    "    \n",
    "plt.subplot(122)\n",
    "g2 = df.loc[df[\"Attrition\"] == \"No\", \"Department\"].value_counts(normalize=True).plot.bar(title= \"Active Employees\", color=\"#1f77b4\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim(0,1)\n",
    "for p in g2.patches:\n",
    "    height = p.get_height()\n",
    "    g2.text(p.get_x()+p.get_width()/2., height+0.01, \"{:1.2f}\".format(height), ha=\"center\", fontsize=14) \n",
    "    \n",
    "# set title and axis labels\n",
    "plt.suptitle(\"Attrition Status by Department\", x=0.5, y=1.05, ha=\"center\", fontsize=16)\n",
    "fig.text(0.5, 0.001, \"Marital Status\", ha=\"center\", fontsize=14)\n",
    "fig.text(0.07, 0.5, \"No of Employee\", va=\"center\", rotation=\"vertical\", fontsize=14)\n",
    "\n",
    "# plt.savefig(\"dept_hist_2.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e30b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(16,4))\n",
    "\n",
    "plt.subplot(131)\n",
    "g1 = df.loc[df['Department'] == 'Research & Development', 'Attrition'].value_counts().sort_values(ascending=True).plot.bar(title= 'Research & Development', color=\"#1f77b4\")\n",
    "g1.set_xticklabels([\"Ex-Employee\", \"Active Employee\"])\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim(0,1000)\n",
    "for p in g1.patches:\n",
    "    height = p.get_height()\n",
    "    g1.text(p.get_x()+p.get_width()/2., height+20, \"{:1.0f}\".format(height), ha=\"center\", fontsize=14) \n",
    "    \n",
    "plt.subplot(132)\n",
    "g2 = df.loc[df['Department'] == 'Sales', 'Attrition'].value_counts().sort_values(ascending=True).plot.bar(title= 'Sales', color=\"#1f77b4\")\n",
    "g2.set_xticklabels([\"Ex-Employee\", \"Active Employee\"])\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim(0,500)\n",
    "for p in g2.patches:\n",
    "    height = p.get_height()\n",
    "    g2.text(p.get_x()+p.get_width()/2., height+10, \"{:1.0f}\".format(height), ha=\"center\", fontsize=14) \n",
    "    \n",
    "plt.subplot(133)\n",
    "g3 = df.loc[df['Department'] == 'Human Resources', 'Attrition'].value_counts().sort_values(ascending=True).plot.bar(title= 'Human Resources', color=\"#1f77b4\")\n",
    "g3.set_xticklabels([\"Ex-Employee\", \"Active Employee\"])\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim(0,100)\n",
    "for p in g3.patches:\n",
    "    height = p.get_height()\n",
    "    g3.text(p.get_x()+p.get_width()/2., height+2, \"{:1.0f}\".format(height), ha=\"center\", fontsize=14) \n",
    "    \n",
    "# set title and axis labels\n",
    "plt.suptitle(\"Attrition Status by Department\", x=0.5, y=1.05, ha=\"center\", fontsize=16)\n",
    "fig.text(0.5, 0.001, \"Department\", ha=\"center\", fontsize=14)\n",
    "fig.text(0.07, 0.5, \"No of Employee\", va=\"center\", rotation=\"vertical\", fontsize=14)\n",
    "\n",
    "# plt.savefig(\"sdept_hist_3.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940a9c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(16,4))\n",
    "\n",
    "plt.subplot(131)\n",
    "g1 = df.loc[df['Department'] == 'Research & Development', 'Attrition'].value_counts(normalize=True).sort_values(ascending=True).plot.bar(title= 'Research & Development', color=\"#1f77b4\")\n",
    "g1.set_xticklabels([\"Ex-Employee\", \"Active Employee\"])\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim(0,1)\n",
    "for p in g1.patches:\n",
    "    height = p.get_height()\n",
    "    g1.text(p.get_x()+p.get_width()/2., height+0.01, \"{:1.2f}\".format(height), ha=\"center\", fontsize=14) \n",
    "    \n",
    "plt.subplot(132)\n",
    "g2 = df.loc[df['Department'] == 'Sales', 'Attrition'].value_counts(normalize=True).sort_values(ascending=True).plot.bar(title= 'Sales', color=\"#1f77b4\")\n",
    "g2.set_xticklabels([\"Ex-Employee\", \"Active Employee\"])\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim(0,1)\n",
    "for p in g2.patches:\n",
    "    height = p.get_height()\n",
    "    g2.text(p.get_x()+p.get_width()/2., height+0.01, \"{:1.2f}\".format(height), ha=\"center\", fontsize=14) \n",
    "    \n",
    "plt.subplot(133)\n",
    "g3 = df.loc[df['Department'] == 'Human Resources', 'Attrition'].value_counts(normalize=True).sort_values(ascending=True).plot.bar(title= 'Human Resources', color=\"#1f77b4\")\n",
    "g3.set_xticklabels([\"Ex-Employee\", \"Active Employee\"])\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim(0,1)\n",
    "for p in g3.patches:\n",
    "    height = p.get_height()\n",
    "    g3.text(p.get_x()+p.get_width()/2., height+0.01, \"{:1.2f}\".format(height), ha=\"center\", fontsize=14) \n",
    "    \n",
    "# set title and axis labels\n",
    "plt.suptitle(\"Attrition Status by Department\", x=0.5, y=1.05, ha=\"center\", fontsize=16)\n",
    "fig.text(0.5, 0.001, \"Employee Status\", ha=\"center\", fontsize=14)\n",
    "fig.text(0.07, 0.5, \"% of Employee\", va=\"center\", rotation=\"vertical\", fontsize=14)\n",
    "\n",
    "# plt.savefig(\"dept_hist_4.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246fb7e5",
   "metadata": {},
   "source": [
    "# Job Role"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253ff9d3",
   "metadata": {},
   "source": [
    "Sale Representative has the highest proportion of leavers, followed by Laboratory Technician and Human Resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1921db4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Employees in the database have several roles on-file\n",
    "df['JobRole'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cb052f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sales Executive              326\n",
    "Research Scientist           292\n",
    "Laboratory Technician        259\n",
    "Manufacturing Director       145\n",
    "Healthcare Representative    131\n",
    "Manager                      102\n",
    "Sales Representative          83\n",
    "Research Director             80\n",
    "Human Resources               52\n",
    "Name: JobRole, dtype: int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69a6ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Employees in the database have several roles on-file\n",
    "df['JobRole'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd67106",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sales Executive              0.221769\n",
    "Research Scientist           0.198639\n",
    "Laboratory Technician        0.176190\n",
    "Manufacturing Director       0.098639\n",
    "Healthcare Representative    0.089116\n",
    "Manager                      0.069388\n",
    "Sales Representative         0.056463\n",
    "Research Director            0.054422\n",
    "Human Resources              0.035374\n",
    "Name: JobRole, dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b8100d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(16,8))\n",
    "\n",
    "plt.subplot(211)\n",
    "g2 = df.loc[df['Attrition'] == 'Yes', 'JobRole'].value_counts().plot.bar(title= 'Ex-Employee', color=\"#1f77b4\")\n",
    "plt.xticks(rotation=10)\n",
    "plt.ylim(0,80)\n",
    "for p in g2.patches:\n",
    "    height = p.get_height()\n",
    "    g2.text(p.get_x()+p.get_width()/2., height+3, \"{:1.0f}\".format(height), ha=\"center\", fontsize=14) \n",
    "\n",
    "fig.subplots_adjust(hspace=0.4)\n",
    "\n",
    "plt.subplot(212)\n",
    "g2 = df.loc[df['Attrition'] == 'No', 'JobRole'].value_counts().plot.bar(title= 'Active Employee', color=\"#1f77b4\")\n",
    "plt.xticks(rotation=10)\n",
    "plt.ylim(0,400)\n",
    "for p in g2.patches:\n",
    "    height = p.get_height()\n",
    "    g2.text(p.get_x()+p.get_width()/2., height+12, \"{:1.0f}\".format(height), ha=\"center\", fontsize=14) \n",
    "\n",
    "# set title and axis labels\n",
    "plt.suptitle('Attrition Status by Job Role', x=0.5, y=0.95, ha=\"center\", fontsize=16)\n",
    "fig.text(0.5, 0.001, 'Job Role', ha='center', fontsize=14)\n",
    "fig.text(0.07, 0.5, 'No of Employee', va='center', rotation='vertical', fontsize=14)\n",
    "\n",
    "# plt.savefig(\"role_hist_1.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7ef942",
   "metadata": {},
   "source": [
    "# Attrition Status by Job Role"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8185e3e3",
   "metadata": {},
   "source": [
    "To visualize the distribution of Attrition Status by Job Role, a bar plot or count plot would be suitable. Here's how you can create the chart using Seaborn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587a4283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Create the count plot\n",
    "sns.countplot(data=df, x='JobRole', hue='Attrition', palette='muted')\n",
    "\n",
    "# Set the title and labels\n",
    "plt.title('Attrition Status by Job Role')\n",
    "plt.xlabel('Job Role')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d94f49c",
   "metadata": {},
   "source": [
    "This code will generate a count plot showing the distribution of Attrition Status across different Job Roles, with Attrition status differentiated by color. Adjust the palette parameter to change the color scheme if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff0f01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(16,8))\n",
    "\n",
    "plt.subplot(211)\n",
    "g2 = df.loc[df['Attrition'] == 'Yes', 'JobRole'].value_counts(normalize=True).plot.bar(title= 'Ex-Employee', color=\"#1f77b4\")\n",
    "plt.xticks(rotation=10)\n",
    "plt.ylim(0,1)\n",
    "for p in g2.patches:\n",
    "    height = p.get_height()\n",
    "    g2.text(p.get_x()+p.get_width()/2., height+0.01, \"{:1.2f}\".format(height), ha=\"center\", fontsize=14) \n",
    "    \n",
    "plt.subplot(212)\n",
    "g2 = df.loc[df['Attrition'] == 'No', 'JobRole'].value_counts(normalize=True).plot.bar(title= 'Active Employee', color=\"#1f77b4\")\n",
    "plt.xticks(rotation=10)\n",
    "plt.ylim(0,1)\n",
    "for p in g2.patches:\n",
    "    height = p.get_height()\n",
    "    g2.text(p.get_x()+p.get_width()/2., height+0.01, \"{:1.2f}\".format(height), ha=\"center\", fontsize=14) \n",
    "\n",
    "fig.subplots_adjust(hspace=0.4)\n",
    "\n",
    "# set title and axis labels\n",
    "plt.suptitle('Attrition Status by Job Role', x=0.5, y=0.95, ha=\"center\", fontsize=16)\n",
    "fig.text(0.5, 0.001, 'Job Role', ha='center', fontsize=14)\n",
    "fig.text(0.07, 0.5, 'No of Employee', va='center', rotation='vertical', fontsize=14)\n",
    "\n",
    "# plt.savefig(\"role_hist_2.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c491306b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_JobRole = pd.DataFrame(columns=[\"Job Role\", \"% of Leavers\"])\n",
    "i=0\n",
    "for field in list(df['JobRole'].unique()):\n",
    "    ratio = df[(df['JobRole']==field)&(df['Attrition']==\"Yes\")].shape[0] / df[df['JobRole']==field].shape[0]\n",
    "    df_JobRole.loc[i] = (field, ratio*100)\n",
    "    i += 1\n",
    "    #print(\"In {}, the ratio of leavers is {:.2f}%\".format(field, ratio*100))    \n",
    "df_JR = df_JobRole.groupby(by=\"Job Role\").sum()\n",
    "g = df_JR.sort_values(by=['% of Leavers'], ascending=False).plot(kind='bar', figsize=(12,4))\n",
    "plt.ylim(0,50)\n",
    "plt.title(\"Proportion of Leavers by Job Role (%)\",  fontsize=16)\n",
    "plt.xticks(rotation=10)\n",
    "for p in g.patches:\n",
    "    height = p.get_height()\n",
    "    g.text(p.get_x()+p.get_width()/2., height+1, \"{:1.1f}\".format(height), ha=\"center\", fontsize=14) \n",
    "\n",
    "# plt.savefig(\"role_hist_3.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be344d7e",
   "metadata": {},
   "source": [
    "# Job Level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197d4495",
   "metadata": {},
   "source": [
    "Employees have an assigned level within the organisation which varies from 1 (staff) to 5 (managerial/director). Employees with an assigned Job Level of \"1\" show the largest normalized proportion of Leavers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bb28fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# breakdown by job level\n",
    "df['JobLevel'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e423e1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "1    543\n",
    "2    534\n",
    "3    218\n",
    "4    106\n",
    "5     69\n",
    "Name: JobLevel, dtype: int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d25936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# breakdown by job level\n",
    "df['JobLevel'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55d594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "1    0.369388\n",
    "2    0.363265\n",
    "3    0.148299\n",
    "4    0.072109\n",
    "5    0.046939\n",
    "Name: JobLevel, dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d2f6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(16,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "g2 = df.loc[df['Attrition'] == 'Yes', 'JobLevel'].value_counts().plot.bar(title= 'Ex-Employee', color=\"#1f77b4\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim(0,170)\n",
    "for p in g2.patches:\n",
    "    height = p.get_height()\n",
    "    g2.text(p.get_x()+p.get_width()/2., height+3, \"{:1.0f}\".format(height), ha=\"center\", fontsize=14) \n",
    "\n",
    "plt.subplot(122)\n",
    "g2 = df.loc[df['Attrition'] == 'No', 'JobLevel'].value_counts().reindex([1,2,3,4,5]).plot.bar(title= 'Active Employee', color=\"#1f77b4\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim(0,600)\n",
    "for p in g2.patches:\n",
    "    height = p.get_height()\n",
    "    g2.text(p.get_x()+p.get_width()/2., height+12, \"{:1.0f}\".format(height), ha=\"center\", fontsize=14) \n",
    "\n",
    "# set title and axis labels\n",
    "plt.suptitle('Attrition Status by Job Level', x=0.5, y=1.05, ha=\"center\", fontsize=16)\n",
    "fig.text(0.5, 0.001, 'Job Level', ha='center', fontsize=14)\n",
    "fig.text(0.07, 0.5, 'No of Employee', va='center', rotation='vertical', fontsize=14)\n",
    "\n",
    "# plt.savefig(\"level_hist_1.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cab49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(16,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "g2 = df.loc[df['Attrition'] == 'Yes', 'JobLevel'].value_counts(normalize=True).plot.bar(title= 'Ex-Employee', color=\"#1f77b4\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim(0,1)\n",
    "for p in g2.patches:\n",
    "    height = p.get_height()\n",
    "    g2.text(p.get_x()+p.get_width()/2., height+0.01, \"{:1.2f}\".format(height), ha=\"center\", fontsize=14) \n",
    "    \n",
    "plt.subplot(122)\n",
    "g2 = df.loc[df['Attrition'] == 'No', 'JobLevel'].value_counts(normalize=True).plot.bar(title= 'Active Employee', color=\"#1f77b4\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim(0,1)\n",
    "for p in g2.patches:\n",
    "    height = p.get_height()\n",
    "    g2.text(p.get_x()+p.get_width()/2., height+0.01, \"{:1.2f}\".format(height), ha=\"center\", fontsize=14) \n",
    "\n",
    "# set title and axis labels\n",
    "plt.suptitle('Attrition Status by Job Level', x=0.5, y=1.05, ha=\"center\", fontsize=16)\n",
    "fig.text(0.5, 0.001, 'Job Level', ha='center', fontsize=14)\n",
    "fig.text(0.07, 0.5, 'No of Employee', va='center', rotation='vertical', fontsize=14)\n",
    "\n",
    "# plt.savefig(\"level_hist_2.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9adafb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_JobLevel = pd.DataFrame(columns=[\"Job Level\", \"% of Leavers\"])\n",
    "i=0\n",
    "for field in list(df['JobLevel'].unique()):\n",
    "    ratio = df[(df['JobLevel']==field)&(df['Attrition']==\"Yes\")].shape[0] / df[df['JobLevel']==field].shape[0]\n",
    "    df_JobLevel.loc[i] = (field, ratio*100)\n",
    "    i += 1\n",
    "    #print(\"In {}, the ratio of leavers is {:.2f}%\".format(field, ratio*100))    \n",
    "df_JL = df_JobLevel.groupby(by=\"Job Level\").sum()\n",
    "g = df_JL.sort_values(by=['% of Leavers'], ascending=False).plot(kind='bar', figsize=(12,4))\n",
    "plt.ylim(0,50)\n",
    "plt.title(\"Proportion of Leavers by Job Level (%)\",  fontsize=16)\n",
    "plt.xticks(rotation=0)\n",
    "for p in g.patches:\n",
    "    height = p.get_height()\n",
    "    g.text(p.get_x()+p.get_width()/2., height+1, \"{:1.1f}\".format(height), ha=\"center\", fontsize=14) \n",
    "\n",
    "# plt.savefig(\"level_hist_3.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373a45f9",
   "metadata": {},
   "source": [
    "# Years at the Company"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f268a46",
   "metadata": {},
   "source": [
    "The average number of years at the company for currently active employees is 7.37 years and ex-employees is 5.13 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159d5569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance from Home\n",
    "print(\"Years At Company for employees is from {} to {} years.\".format(df['YearsAtCompany'].min(), df['YearsAtCompany'].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bea0f5f",
   "metadata": {},
   "source": [
    "Years At Company for employees is from 0 to 40 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fc61ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex-Employees\n",
    "print(\"Ex-Employees:\")\n",
    "print(\"Average Years At Company of Ex-Employees = {:1.2f} years\".format(np.mean(df.loc[df['Attrition'] == 'Yes', 'YearsAtCompany'])))\n",
    "print(\"Standard Deviation = {:1.2f}\".format(np.std(df.loc[df['Attrition'] == 'Yes', 'YearsAtCompany'])))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "75f5c45b",
   "metadata": {},
   "source": [
    "Ex-Employees:\n",
    "Average Years At Company of Ex-Employees = 5.13 years\n",
    "Standard Deviation = 5.94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca29dd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Active Employees\n",
    "print(\"Active Employees:\")\n",
    "print(\"Average Years At Company of Active Employees = {:1.2f} years\".format(np.mean(df.loc[df['Attrition'] == 'No', 'YearsAtCompany'])))\n",
    "print(\"Standard Deviation = {:1.2f}\".format(np.std(df.loc[df['Attrition'] == 'No', 'YearsAtCompany'])))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4dc9a4e4",
   "metadata": {},
   "source": [
    "Active Employees:\n",
    "Average Years At Company of Active Employees = 7.37 years\n",
    "Standard Deviation = 6.09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8ae2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel density estimation (KDE) plot \n",
    "\n",
    "plt.subplots(figsize=(12,4))\n",
    "\n",
    "target_0 = df.loc[df[\"Attrition\"] == \"No\"]\n",
    "target_1 = df.loc[df[\"Attrition\"] == \"Yes\"]\n",
    "\n",
    "sns.distplot(target_0[[\"YearsAtCompany\"]], hist=False, label=\"Active Employees\", color=\"#2ca02c\")\n",
    "sns.distplot(target_1[[\"YearsAtCompany\"]], hist=False, label=\"Ex-Exployees\", color=\"#1f77b4\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Years At Company\", fontsize=12)\n",
    "plt.ylabel(\"Density\", fontsize=12)\n",
    "plt.title(\"Years At Company Distribution by Attrition Status\", fontsize=14)\n",
    "\n",
    "# plt.savefig(\"year_kde_1.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde3bf05",
   "metadata": {},
   "source": [
    "# Years At Company  Distribution by Attrition Status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9851f886",
   "metadata": {},
   "source": [
    "\n",
    "To visualize the distribution of \"Years At Company\" by \"Attrition Status,\" you can use Seaborn's histplot function. Here's how you can create the chart:\n",
    "\n",
    "python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b171e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create the distribution plot\n",
    "sns.histplot(data=df, x='YearsAtCompany', hue='Attrition', kde=True, bins=30, palette='muted')\n",
    "\n",
    "# Set the title and labels\n",
    "plt.title('Years At Company Distribution by Attrition Status')\n",
    "plt.xlabel('Years At Company')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1db390",
   "metadata": {},
   "source": [
    "This code will generate a histogram showing the distribution of \"Years At Company,\" with the Attrition status differentiated by color. Adjust the bins parameter to change the number of bins in the histogram, and modify the palette parameter to change the color scheme if neede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8736eafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histogram\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "fig.set_size_inches(12,4)\n",
    "\n",
    "target_0[['YearsAtCompany']].hist(bins=20, ax=axes[0])\n",
    "axes[0].set_title('Active Employees')\n",
    "\n",
    "target_1[['YearsAtCompany']].hist(bins=20, ax=axes[1])\n",
    "axes[1].set_title('Ex-Employees')\n",
    "\n",
    "fig.text(0.5, 0.01, 'Years At Company', ha='center', fontsize=12)\n",
    "fig.text(0.07, 0.5, 'No of Employee', va='center', rotation='vertical', fontsize=12)\n",
    "\n",
    "# plt.savefig(\"year_hist.png\"\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ab7300",
   "metadata": {},
   "source": [
    "# Overtime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18733f2",
   "metadata": {},
   "source": [
    "Some employees have overtime commitments. The data clearly show that there is significant larger portion of employees with OT that have left the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbe05db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# breakdown by overtime\n",
    "df['OverTime'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1127b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "No     1054\n",
    "Yes     416\n",
    "Name: OverTime, dtype: int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9894fb22",
   "metadata": {},
   "outputs": [],
   "source": [
    " breakdown by overtime\n",
    "df['OverTime'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f812d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "No     0.717007\n",
    "Yes    0.282993\n",
    "Name: OverTime, dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27db619",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(16,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "g2 = df.loc[df['Attrition'] == 'Yes', 'OverTime'].value_counts().plot.bar(title= 'Ex-Employee', color=\"#1f77b4\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim(0,170)\n",
    "for p in g2.patches:\n",
    "    height = p.get_height()\n",
    "    g2.text(p.get_x()+p.get_width()/2., height+3, \"{:1.0f}\".format(height), ha=\"center\", fontsize=14) \n",
    "\n",
    "plt.subplot(122)\n",
    "g2 = df.loc[df['Attrition'] == 'No', 'OverTime'].value_counts().reindex([\"Yes\", \"No\"]).plot.bar(title= 'Active Employee', color=\"#1f77b4\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim(0,1200)\n",
    "for p in g2.patches:\n",
    "    height = p.get_height()\n",
    "    g2.text(p.get_x()+p.get_width()/2., height+12, \"{:1.0f}\".format(height), ha=\"center\", fontsize=14) \n",
    "\n",
    "# set title and axis labels\n",
    "plt.suptitle('Attrition Status by OverTime', x=0.5, y=1.05, ha=\"center\", fontsize=16)\n",
    "fig.text(0.5, 0.001, 'Job Level', ha='center', fontsize=14)\n",
    "fig.text(0.07, 0.5, 'No of Employee', va='center', rotation='vertical', fontsize=14)\n",
    "\n",
    "# plt.savefig(\"ot_hist_1.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a47922",
   "metadata": {},
   "source": [
    "# Attrition Stuatus by OverTime "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf038d3f",
   "metadata": {},
   "source": [
    "To visualize the distribution of Attrition Status by Overtime, you can use a count plot or bar plot. Here's how you can create the chart using Seaborn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d47aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the figure size\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Create the count plot\n",
    "sns.countplot(data=df, x='OverTime', hue='Attrition', palette='muted')\n",
    "\n",
    "# Set the title and labels\n",
    "plt.title('Attrition Status by Overtime')\n",
    "plt.xlabel('Overtime')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1366975e",
   "metadata": {},
   "source": [
    "This code will generate a count plot showing the distribution of Attrition Status across Overtime categories, with Attrition status differentiated by color. Adjust the palette parameter to change the color scheme if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715ee0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(16,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "g2 = df.loc[df['Attrition'] == 'Yes', 'OverTime'].value_counts(normalize=True).plot.bar(title= 'Ex-Employee', color=\"#1f77b4\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim(0,1)\n",
    "for p in g2.patches:\n",
    "    height = p.get_height()\n",
    "    g2.text(p.get_x()+p.get_width()/2., height+0.01, \"{:1.2f}\".format(height), ha=\"center\", fontsize=14) \n",
    "    \n",
    "plt.subplot(122)\n",
    "g2 = df.loc[df['Attrition'] == 'No', 'OverTime'].value_counts(normalize=True).reindex([\"Yes\", \"No\"]).plot.bar(title= 'Active Employee', color=\"#1f77b4\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim(0,1)\n",
    "for p in g2.patches:\n",
    "    height = p.get_height()\n",
    "    g2.text(p.get_x()+p.get_width()/2., height+0.01, \"{:1.2f}\".format(height), ha=\"center\", fontsize=14) \n",
    "\n",
    "# set title and axis labels\n",
    "plt.suptitle('Attrition Status by OverTime', x=0.5, y=1.05, ha=\"center\", fontsize=16)\n",
    "fig.text(0.5, 0.001, 'Job Level', ha='center', fontsize=14)\n",
    "fig.text(0.07, 0.5, 'No of Employee', va='center', rotation='vertical', fontsize=14)\n",
    "\n",
    "# plt.savefig(\"ot_hist_2.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f3cbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OverTime = pd.DataFrame(columns=[\"OverTime\", \"% of Leavers\"])\n",
    "i=0\n",
    "for field in list(df['OverTime'].unique()):\n",
    "    ratio = df[(df['OverTime']==field)&(df['Attrition']==\"Yes\")].shape[0] / df[df['OverTime']==field].shape[0]\n",
    "    df_OverTime.loc[i] = (field, ratio*100)\n",
    "    i += 1\n",
    "    #print(\"In {}, the ratio of leavers is {:.2f}%\".format(field, ratio*100))    \n",
    "df_OT = df_OverTime.groupby(by=\"OverTime\").sum()\n",
    "g = df_OT.sort_values(by=['% of Leavers'], ascending=False).plot(kind='bar', figsize=(12,4))\n",
    "plt.ylim(0,50)\n",
    "plt.title(\"Proportion of Leavers by OverTime (%)\",  fontsize=16)\n",
    "plt.xticks(rotation=0)\n",
    "for p in g.patches:\n",
    "    height = p.get_height()\n",
    "    g.text(p.get_x()+p.get_width()/2., height+1, \"{:1.1f}\".format(height), ha=\"center\", fontsize=14) \n",
    "\n",
    "# plt.savefig(\"ot_hist_3.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a5da34",
   "metadata": {},
   "source": [
    "# Proportion Of Leavers by Work Life Balance(%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04019fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Filter the dataframe to include only employees who have left (Attrition == 'Yes')\n",
    "leavers_df = df[df['Attrition'] == 'Yes']\n",
    "\n",
    "# Calculate the proportion of leavers by Work Life Balance percentage\n",
    "proportion_leavers = leavers_df.groupby('WorkLifeBalance')['Attrition'].count() / len(leavers_df)\n",
    "\n",
    "# Plot the proportion of leavers by Work Life Balance percentage\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=proportion_leavers.index, y=proportion_leavers.values, color='skyblue')\n",
    "plt.title('Proportion of Leavers by Work Life Balance (%)')\n",
    "plt.xlabel('Work Life Balance (%)')\n",
    "plt.ylabel('Proportion of Leavers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936c62fc",
   "metadata": {},
   "source": [
    "This code calculates the proportion of leavers for each Work Life Balance percentage category and then creates a bar plot to visualize these proportions. Adjust the figure size, color, and other parameters as needed for your visualization preferences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff37ac8",
   "metadata": {},
   "source": [
    "# Monthly Income"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61bae24",
   "metadata": {},
   "source": [
    "Employee Monthly Income varies from 1,009 to\n",
    "19,999."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ff00bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly Income\n",
    "print(\"Monthly Income for employees is from ${} to ${}.\".format(df['MonthlyIncome'].min(), df['MonthlyIncome'].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb1f1b9",
   "metadata": {},
   "source": [
    "Monthly Income for employees is from $1009 to $19999."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cde7efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex-Employees\n",
    "print(\"Ex-Employees:\")\n",
    "print(\"Average Monthly Income of Ex-Employees = ${:1.2f}\".format(np.mean(df.loc[df['Attrition'] == 'Yes', 'MonthlyIncome'])))\n",
    "print(\"Standard Deviation = ${:1.2f}\".format(np.std(df.loc[df['Attrition'] == 'Yes', 'MonthlyIncome'])))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a03d3ef7",
   "metadata": {},
   "source": [
    "Ex-Employees:\n",
    "Average Monthly Income of Ex-Employees = $4787.09\n",
    "Standard Deviation = $3632.52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc50aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Active Employees\n",
    "print(\"Active Employees:\")\n",
    "print(\"Average Monthly Income of Active Employees = ${:1.2f}\".format(np.mean(df.loc[df['Attrition'] == 'No', 'MonthlyIncome'])))\n",
    "print(\"Standard Deviation = ${:1.2f}\".format(np.std(df.loc[df['Attrition'] == 'No', 'MonthlyIncome'])))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4d720f43",
   "metadata": {},
   "source": [
    "Active Employees:\n",
    "Average Monthly Income of Active Employees = $6832.74\n",
    "Standard Deviation = $4816.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dd0b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel density estimation (KDE) plot \n",
    "\n",
    "plt.subplots(figsize=(12,4))\n",
    "\n",
    "target_0 = df.loc[df[\"Attrition\"] == \"No\"]\n",
    "target_1 = df.loc[df[\"Attrition\"] == \"Yes\"]\n",
    "\n",
    "sns.distplot(target_0[[\"MonthlyIncome\"]], hist=False, label=\"Active Employees\", color=\"#2ca02c\")\n",
    "sns.distplot(target_1[[\"MonthlyIncome\"]], hist=False, label=\"Ex-Exployees\", color=\"#1f77b4\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Monthly Income\", fontsize=12)\n",
    "plt.ylabel(\"Density\", fontsize=12)\n",
    "plt.title(\"Distribution of Monthly Income by Attrition Status\", fontsize=14)\n",
    "\n",
    "# plt.savefig(\"income_kde_1.png\", bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4768284",
   "metadata": {},
   "source": [
    "You can get negative x-values ending up with some positive density from a kernel density estimate, simply because of the way KDEs work. Refer https://stats.stackexchange.com/questions/109549/negative-density-for-non-negative-variables and https://www.youtube.com/watch?v=R6_LR-f6Tt4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176e3945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel density estimation (KDE) plot \n",
    "\n",
    "plt.subplots(figsize=(12,4))\n",
    "\n",
    "target_0 = df.loc[df[\"Attrition\"] == \"No\"]\n",
    "target_1 = df.loc[df[\"Attrition\"] == \"Yes\"]\n",
    "\n",
    "sns.distplot(target_0[[\"MonthlyIncome\"]], hist=False, label=\"Active Employees\", color=\"#2ca02c\")\n",
    "sns.distplot(target_1[[\"MonthlyIncome\"]], hist=False, label=\"Ex-Exployees\", color=\"#1f77b4\")\n",
    "plt.legend()\n",
    "plt.xlim(df[\"MonthlyIncome\"].min(), df[\"MonthlyIncome\"].max())\n",
    "plt.xlabel(\"Monthly Income\", fontsize=12)\n",
    "plt.ylabel(\"Density\", fontsize=12)\n",
    "plt.title(\"Distribution of Monthly Income by Attrition Status\", fontsize=14)\n",
    "\n",
    "# plt.savefig(\"income_kde_2.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5d8f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histogram\n",
    "fig, axes = plt.subplots(1, 2)\n",
    "fig.set_size_inches(12,4)\n",
    "\n",
    "target_0[['MonthlyIncome']].hist(bins=20, ax=axes[0])\n",
    "axes[0].set_title('Active Employees')\n",
    "\n",
    "target_1[['MonthlyIncome']].hist(bins=20, ax=axes[1])\n",
    "axes[1].set_title('Ex-Employees')\n",
    "\n",
    "fig.text(0.5, 0.01, 'Monthly Income', ha='center', fontsize=12)\n",
    "fig.text(0.07, 0.5, 'No of Employee', va='center', rotation='vertical', fontsize=12)\n",
    "\n",
    "# plt.savefig(\"income_hist.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4937515b",
   "metadata": {},
   "source": [
    "# Target Variable: Attrition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28078504",
   "metadata": {},
   "source": [
    "The feature “Attrition” is what this Machine Learning problem is about. We are trying to predict the value of the feature ‘Attrition’ by using other related features associated with the employee’s personal and professional history."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ff8052",
   "metadata": {},
   "source": [
    "In the supplied dataset, the percentage of Current Employees is 83.9% and of Ex-employees is 16.1%. Hence, this is an imbalanced class problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb85165c",
   "metadata": {},
   "source": [
    "Machine learning algorithms typically work best when the number of instances of each classes are roughly equal. We will have to address this target feature imbalance prior to implementing our Machine Learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebd59c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attrition indicates if the employee is currently active ('No') or has left the company ('Yes')\n",
    "df['Attrition'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940647fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "No     1233\n",
    "Yes     237\n",
    "Name: Attrition, dtype: int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04a3386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attrition indicates if the employee is currently active ('No') or has left the company ('Yes')\n",
    "df['Attrition'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0309006",
   "metadata": {},
   "outputs": [],
   "source": [
    "No     0.838776\n",
    "Yes    0.161224\n",
    "Name: Attrition, dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee014559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Attrition'].value_counts().plot(kind='hist', xTitle='Attrition', yTitle='count', title='Attrition Distribution')\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(16,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "g1 = df['Attrition'].value_counts().reindex([\"Yes\", \"No\"]).plot.bar(color=\"#1f77b4\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylabel(\"No of Employee\")\n",
    "plt.ylim(0,1500)\n",
    "for p in g1.patches:\n",
    "    height = p.get_height()\n",
    "    g1.text(p.get_x()+p.get_width()/2., height+20, \"{:1.0f}\".format(height), ha=\"center\", fontsize=14) \n",
    "    \n",
    "plt.subplot(122)\n",
    "g2 = df['Attrition'].value_counts(normalize=True).reindex([\"Yes\", \"No\"]).plot.bar( color=\"#1f77b4\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylabel(\"% of Employee\")\n",
    "plt.ylim(0,1)\n",
    "for p in g2.patches:\n",
    "    height = p.get_height()\n",
    "    g2.text(p.get_x()+p.get_width()/2., height+0.01, \"{:1.2f}\".format(height), ha=\"center\", fontsize=14) \n",
    "    \n",
    "# set title and axis labels\n",
    "plt.suptitle(\"Attrition Status\", x=0.5, y=1.05, ha=\"center\", fontsize=16)\n",
    "# fig.text(0.5, 0.001, 'Attrition Status', ha='center', fontsize=14)\n",
    "# fig.text(0.07, 0.5, 'No of Employee', va='center', rotation='vertical', fontsize=14)\n",
    "\n",
    "# plt.savefig(\"att_hist_1.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa967ba",
   "metadata": {},
   "source": [
    "# Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53ffb99",
   "metadata": {},
   "source": [
    "Let's take a look at some of most significant correlations. It is worth remembering that correlation coefficients only measure linear correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd045573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find correlations with the target and sort\n",
    "df_corr = df.copy()\n",
    "df_corr['Target'] = df_corr['Attrition'].apply(lambda x: 0 if x == 'No' else 1)\n",
    "df_corr = df_corr.drop(['Attrition', 'EmployeeCount', 'EmployeeNumber', 'StandardHours', 'Over18'], axis=1)\n",
    "correlations = df_corr.corr()['Target'].sort_values()\n",
    "print('Most Positive Correlations: \\n', correlations.tail(5))\n",
    "print('\\nMost Negative Correlations: \\n', correlations.head(5))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9507ca8f",
   "metadata": {},
   "source": [
    "Most Positive Correlations: \n",
    " PerformanceRating     0.002889\n",
    "MonthlyRate           0.015170\n",
    "NumCompaniesWorked    0.043494\n",
    "DistanceFromHome      0.077924\n",
    "Target                1.000000\n",
    "Name: Target, dtype: float64\n",
    "\n",
    "Most Negative Correlations: \n",
    " TotalWorkingYears    -0.171063\n",
    "JobLevel             -0.169105\n",
    "YearsInCurrentRole   -0.160545\n",
    "MonthlyIncome        -0.159840\n",
    "Age                  -0.159205\n",
    "Name: Target, dtype: float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b6e28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the correlation matrix\n",
    "corr = df_corr.corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56142c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\tAge\tDailyRate\tDistanceFromHome\tEducation\tEnvironmentSatisfaction\tHourlyRate\tJobInvolvement\tJobLevel\tJobSatisfaction\tMonthlyIncome\t...\tRelationshipSatisfaction\tStockOptionLevel\tTotalWorkingYears\tTrainingTimesLastYear\tWorkLifeBalance\tYearsAtCompany\tYearsInCurrentRole\tYearsSinceLastPromotion\tYearsWithCurrManager\tTarget\n",
    "Age\t1.000000\t0.010661\t-0.001686\t0.208034\t0.010146\t0.024287\t0.029820\t0.509604\t-0.004892\t0.497855\t...\t0.053535\t0.037510\t0.680381\t-0.019621\t-0.021490\t0.311309\t0.212901\t0.216513\t0.202089\t-0.159205\n",
    "DailyRate\t0.010661\t1.000000\t-0.004985\t-0.016806\t0.018355\t0.023381\t0.046135\t0.002966\t0.030571\t0.007707\t...\t0.007846\t0.042143\t0.014515\t0.002453\t-0.037848\t-0.034055\t0.009932\t-0.033229\t-0.026363\t-0.056652\n",
    "DistanceFromHome\t-0.001686\t-0.004985\t1.000000\t0.021042\t-0.016075\t0.031131\t0.008783\t0.005303\t-0.003669\t-0.017014\t...\t0.006557\t0.044872\t0.004628\t-0.036942\t-0.026556\t0.009508\t0.018845\t0.010029\t0.014406\t0.077924\n",
    "Education\t0.208034\t-0.016806\t0.021042\t1.000000\t-0.027128\t0.016775\t0.042438\t0.101589\t-0.011296\t0.094961\t...\t-0.009118\t0.018422\t0.148280\t-0.025100\t0.009819\t0.069114\t0.060236\t0.054254\t0.069065\t-0.031373\n",
    "EnvironmentSatisfaction\t0.010146\t0.018355\t-0.016075\t-0.027128\t1.000000\t-0.049857\t-0.008278\t0.001212\t-0.006784\t-0.006259\t...\t0.007665\t0.003432\t-0.002693\t-0.019359\t0.027627\t0.001458\t0.018007\t0.016194\t-0.004999\t-0.103369\n",
    "HourlyRate\t0.024287\t0.023381\t0.031131\t0.016775\t-0.049857\t1.000000\t0.042861\t-0.027853\t-0.071335\t-0.015794\t...\t0.001330\t0.050263\t-0.002334\t-0.008548\t-0.004607\t-0.019582\t-0.024106\t-0.026716\t-0.020123\t-0.006846\n",
    "JobInvolvement\t0.029820\t0.046135\t0.008783\t0.042438\t-0.008278\t0.042861\t1.000000\t-0.012630\t-0.021476\t-0.015271\t...\t0.034297\t0.021523\t-0.005533\t-0.015338\t-0.014617\t-0.021355\t0.008717\t-0.024184\t0.025976\t-0.130016\n",
    "JobLevel\t0.509604\t0.002966\t0.005303\t0.101589\t0.001212\t-0.027853\t-0.012630\t1.000000\t-0.001944\t0.950300\t...\t0.021642\t0.013984\t0.782208\t-0.018191\t0.037818\t0.534739\t0.389447\t0.353885\t0.375281\t-0.169105\n",
    "JobSatisfaction\t-0.004892\t0.030571\t-0.003669\t-0.011296\t-0.006784\t-0.071335\t-0.021476\t-0.001944\t1.000000\t-0.007157\t...\t-0.012454\t0.010690\t-0.020185\t-0.005779\t-0.019459\t-0.003803\t-0.002305\t-0.018214\t-0.027656\t-0.103481\n",
    "MonthlyIncome\t0.497855\t0.007707\t-0.017014\t0.094961\t-0.006259\t-0.015794\t-0.015271\t0.950300\t-0.007157\t1.000000\t...\t0.025873\t0.005408\t0.772893\t-0.021736\t0.030683\t0.514285\t0.363818\t0.344978\t0.344079\t-0.159840\n",
    "MonthlyRate\t0.028051\t-0.032182\t0.027473\t-0.026084\t0.037600\t-0.015297\t-0.016322\t0.039563\t0.000644\t0.034814\t...\t-0.004085\t-0.034323\t0.026442\t0.001467\t0.007963\t-0.023655\t-0.012815\t0.001567\t-0.036746\t0.015170\n",
    "NumCompaniesWorked\t0.299635\t0.038153\t-0.029251\t0.126317\t0.012594\t0.022157\t0.015012\t0.142501\t-0.055699\t0.149515\t...\t0.052733\t0.030075\t0.237639\t-0.066054\t-0.008366\t-0.118421\t-0.090754\t-0.036814\t-0.110319\t0.043494\n",
    "PercentSalaryHike\t0.003634\t0.022704\t0.040235\t-0.011111\t-0.031701\t-0.009062\t-0.017205\t-0.034730\t0.020002\t-0.027269\t...\t-0.040490\t0.007528\t-0.020608\t-0.005221\t-0.003280\t-0.035991\t-0.001520\t-0.022154\t-0.011985\t-0.013478\n",
    "PerformanceRating\t0.001904\t0.000473\t0.027110\t-0.024539\t-0.029548\t-0.002172\t-0.029071\t-0.021222\t0.002297\t-0.017120\t...\t-0.031351\t0.003506\t0.006744\t-0.015579\t0.002572\t0.003435\t0.034986\t0.017896\t0.022827\t0.002889\n",
    "RelationshipSatisfaction\t0.053535\t0.007846\t0.006557\t-0.009118\t0.007665\t0.001330\t0.034297\t0.021642\t-0.012454\t0.025873\t...\t1.000000\t-0.045952\t0.024054\t0.002497\t0.019604\t0.019367\t-0.015123\t0.033493\t-0.000867\t-0.045872\n",
    "StockOptionLevel\t0.037510\t0.042143\t0.044872\t0.018422\t0.003432\t0.050263\t0.021523\t0.013984\t0.010690\t0.005408\t...\t-0.045952\t1.000000\t0.010136\t0.011274\t0.004129\t0.015058\t0.050818\t0.014352\t0.024698\t-0.137145\n",
    "TotalWorkingYears\t0.680381\t0.014515\t0.004628\t0.148280\t-0.002693\t-0.002334\t-0.005533\t0.782208\t-0.020185\t0.772893\t...\t0.024054\t0.010136\t1.000000\t-0.035662\t0.001008\t0.628133\t0.460365\t0.404858\t0.459188\t-0.171063\n",
    "TrainingTimesLastYear\t-0.019621\t0.002453\t-0.036942\t-0.025100\t-0.019359\t-0.008548\t-0.015338\t-0.018191\t-0.005779\t-0.021736\t...\t0.002497\t0.011274\t-0.035662\t1.000000\t0.028072\t0.003569\t-0.005738\t-0.002067\t-0.004096\t-0.059478\n",
    "WorkLifeBalance\t-0.021490\t-0.037848\t-0.026556\t0.009819\t0.027627\t-0.004607\t-0.014617\t0.037818\t-0.019459\t0.030683\t...\t0.019604\t0.004129\t0.001008\t0.028072\t1.000000\t0.012089\t0.049856\t0.008941\t0.002759\t-0.063939\n",
    "YearsAtCompany\t0.311309\t-0.034055\t0.009508\t0.069114\t0.001458\t-0.019582\t-0.021355\t0.534739\t-0.003803\t0.514285\t...\t0.019367\t0.015058\t0.628133\t0.003569\t0.012089\t1.000000\t0.758754\t0.618409\t0.769212\t-0.134392\n",
    "YearsInCurrentRole\t0.212901\t0.009932\t0.018845\t0.060236\t0.018007\t-0.024106\t0.008717\t0.389447\t-0.002305\t0.363818\t...\t-0.015123\t0.050818\t0.460365\t-0.005738\t0.049856\t0.758754\t1.000000\t0.548056\t0.714365\t-0.160545\n",
    "YearsSinceLastPromotion\t0.216513\t-0.033229\t0.010029\t0.054254\t0.016194\t-0.026716\t-0.024184\t0.353885\t-0.018214\t0.344978\t...\t0.033493\t0.014352\t0.404858\t-0.002067\t0.008941\t0.618409\t0.548056\t1.000000\t0.510224\t-0.033019\n",
    "YearsWithCurrManager\t0.202089\t-0.026363\t0.014406\t0.069065\t-0.004999\t-0.020123\t0.025976\t0.375281\t-0.027656\t0.344079\t...\t-0.000867\t0.024698\t0.459188\t-0.004096\t0.002759\t0.769212\t0.714365\t0.510224\t1.000000\t-0.156199\n",
    "Target\t-0.159205\t-0.056652\t0.077924\t-0.031373\t-0.103369\t-0.006846\t-0.130016\t-0.169105\t-0.103481\t-0.159840\t...\t-0.045872\t-0.137145\t-0.171063\t-0.059478\t-0.063939\t-0.134392\t-0.160545\t-0.033019\t-0.156199\t1.000000\n",
    "24 rows × 24 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fdb70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set figure size\n",
    "plt.figure(figsize=(14, 14))\n",
    "\n",
    "# generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "fig = sns.heatmap(corr, vmax=1, square=True, cmap=\"BuPu\", linewidths=.1, annot=False, mask=mask)\n",
    "\n",
    "# fig.get_figure().savefig(\"corr_heatmap.png\", bbox_inches=\"tight\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f53e217",
   "metadata": {},
   "source": [
    "# Pre-processing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be64f0a",
   "metadata": {},
   "source": [
    "In this section, we undertake data pre-processing steps to prepare the datasets for Machine Learning algorithm implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df48a93",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7b386a",
   "metadata": {},
   "source": [
    "Machine Learning algorithms can typically only have numerical values as their predictor variables. Hence Label Encoding becomes necessary as they encode categorical labels with numerical values. To avoid introducing feature importance for categorical features with large numbers of unique values, we will use both Label Encoding and One-Hot Encoding as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e49683",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a925258",
   "metadata": {},
   "outputs": [],
   "source": [
    "Age\tAttrition\tBusinessTravel\tDailyRate\tDepartment\tDistanceFromHome\tEducation\tEducationField\tEmployeeCount\tEmployeeNumber\t...\tRelationshipSatisfaction\tStandardHours\tStockOptionLevel\tTotalWorkingYears\tTrainingTimesLastYear\tWorkLifeBalance\tYearsAtCompany\tYearsInCurrentRole\tYearsSinceLastPromotion\tYearsWithCurrManager\n",
    "0\t41\t1\tTravel_Rarely\t1102\tSales\t1\t2\tLife Sciences\t1\t1\t...\t1\t80\t0\t8\t0\t1\t6\t4\t0\t5\n",
    "1\t49\t0\tTravel_Frequently\t279\tResearch & Development\t8\t1\tLife Sciences\t1\t2\t...\t4\t80\t1\t10\t3\t3\t10\t7\t1\t7\n",
    "2\t37\t1\tTravel_Rarely\t1373\tResearch & Development\t2\t2\tOther\t1\t4\t...\t2\t80\t0\t7\t3\t3\t0\t0\t0\t0\n",
    "3\t33\t0\tTravel_Frequently\t1392\tResearch & Development\t3\t4\tLife Sciences\t1\t5\t...\t3\t80\t0\t8\t3\t3\t8\t7\t3\t0\n",
    "4\t27\t0\tTravel_Rarely\t591\tResearch & Development\t2\t1\tMedical\t1\t7\t...\t4\t80\t1\t6\t3\t3\t2\t2\t2\t2\n",
    "5 rows × 35 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24bbc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert rest of categorical variable into dummy\n",
    "df = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3a45b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704ebd24",
   "metadata": {},
   "source": [
    "(1470, 54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e07da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Age\tAttrition\tDailyRate\tDistanceFromHome\tEducation\tEmployeeCount\tEmployeeNumber\tEnvironmentSatisfaction\tGender\tHourlyRate\t...\tJobRole_Laboratory Technician\tJobRole_Manager\tJobRole_Manufacturing Director\tJobRole_Research Director\tJobRole_Research Scientist\tJobRole_Sales Executive\tJobRole_Sales Representative\tMaritalStatus_Divorced\tMaritalStatus_Married\tMaritalStatus_Single\n",
    "0\t41\t1\t1102\t1\t2\t1\t1\t2\t0\t94\t...\t0\t0\t0\t0\t0\t1\t0\t0\t0\t1\n",
    "1\t49\t0\t279\t8\t1\t1\t2\t3\t1\t61\t...\t0\t0\t0\t0\t1\t0\t0\t0\t1\t0\n",
    "2\t37\t1\t1373\t2\t2\t1\t4\t4\t1\t92\t...\t1\t0\t0\t0\t0\t0\t0\t0\t0\t1\n",
    "3\t33\t0\t1392\t3\t4\t1\t5\t4\t0\t56\t...\t0\t0\t0\t0\t1\t0\t0\t0\t1\t0\n",
    "4\t27\t0\t591\t2\t1\t1\t7\t1\t1\t40\t...\t1\t0\t0\t0\t0\t0\t0\t0\t1\t0\n",
    "5 rows × 54 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71aef89a",
   "metadata": {},
   "source": [
    "# Splitting data into training and testing sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a96358",
   "metadata": {},
   "source": [
    "Prior to implementating or applying any Machine Learning algorithms, we must split the dataset into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d48383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the target to a new dataframe and convert it to a numerical type\n",
    "y = df['Attrition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1840f407",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(y))\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a47b55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "<class 'pandas.core.series.Series'>\n",
    "0    1\n",
    "1    0\n",
    "2    1\n",
    "3    0\n",
    "4    0\n",
    "Name: Attrition, dtype: int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38f8815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the target and redundant features from the dataset\n",
    "X = df.drop(['Attrition', 'EmployeeCount', 'EmployeeNumber', 'StandardHours', 'Over18'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a20ebb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d37254ec",
   "metadata": {},
   "source": [
    "(1470, 49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2061407",
   "metadata": {},
   "outputs": [],
   "source": [
    "\tAge\tDailyRate\tDistanceFromHome\tEducation\tEnvironmentSatisfaction\tGender\tHourlyRate\tJobInvolvement\tJobLevel\tJobSatisfaction\t...\tJobRole_Laboratory Technician\tJobRole_Manager\tJobRole_Manufacturing Director\tJobRole_Research Director\tJobRole_Research Scientist\tJobRole_Sales Executive\tJobRole_Sales Representative\tMaritalStatus_Divorced\tMaritalStatus_Married\tMaritalStatus_Single\n",
    "0\t41\t1102\t1\t2\t2\t0\t94\t3\t2\t4\t...\t0\t0\t0\t0\t0\t1\t0\t0\t0\t1\n",
    "1\t49\t279\t8\t1\t3\t1\t61\t2\t2\t2\t...\t0\t0\t0\t0\t1\t0\t0\t0\t1\t0\n",
    "2\t37\t1373\t2\t2\t4\t1\t92\t2\t1\t3\t...\t1\t0\t0\t0\t0\t0\t0\t0\t0\t1\n",
    "3\t33\t1392\t3\t4\t4\t0\t56\t3\t1\t3\t...\t0\t0\t0\t0\t1\t0\t0\t0\t1\t0\n",
    "4\t27\t591\t2\t1\t1\t1\t40\t3\t1\t2\t...\t1\t0\t0\t0\t0\t0\t0\t0\t1\t0\n",
    "5 rows × 49 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bacd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we have class imbalance (i.e. more employees with turnover=0 than turnover=1)\n",
    "# let's use stratify=y to maintain the same ratio as in the training dataset when splitting the dataset\n",
    "\n",
    "# import library\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0, stratify=y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2559f893",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of X_train dataset: \", X_train.shape)\n",
    "print(\"Shape of y_train dataset: \", y_train.shape)\n",
    "print(\"Shape of X_test dataset: \", X_test.shape)\n",
    "print(\"Shape of y_test dataset: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ee1aff61",
   "metadata": {},
   "source": [
    "Shape of X_train dataset:  (1102, 49)\n",
    "Shape of y_train dataset:  (1102,)\n",
    "Shape of X_test dataset:  (368, 49)\n",
    "Shape of y_test dataset:  (368,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ecf31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27a2a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\tAge\tDailyRate\tDistanceFromHome\tEducation\tEnvironmentSatisfaction\tGender\tHourlyRate\tJobInvolvement\tJobLevel\tJobSatisfaction\t...\tJobRole_Laboratory Technician\tJobRole_Manager\tJobRole_Manufacturing Director\tJobRole_Research Director\tJobRole_Research Scientist\tJobRole_Sales Executive\tJobRole_Sales Representative\tMaritalStatus_Divorced\tMaritalStatus_Married\tMaritalStatus_Single\n",
    "619\t33\t586\t1\t3\t1\t1\t48\t4\t2\t1\t...\t0\t0\t0\t0\t0\t1\t0\t1\t0\t0\n",
    "779\t51\t1323\t4\t4\t1\t1\t34\t3\t1\t3\t...\t0\t0\t0\t0\t1\t0\t0\t0\t1\t0\n",
    "627\t52\t890\t25\t4\t3\t0\t81\t2\t4\t4\t...\t0\t0\t1\t0\t0\t0\t0\t0\t1\t0\n",
    "301\t18\t812\t10\t3\t4\t0\t69\t2\t1\t3\t...\t0\t0\t0\t0\t0\t0\t1\t0\t0\t1\n",
    "308\t58\t390\t1\t4\t4\t1\t32\t1\t2\t3\t...\t0\t0\t0\t0\t0\t0\t0\t1\t0\t0\n",
    "5 rows × 49 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c9a3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1c3453",
   "metadata": {},
   "outputs": [],
   "source": [
    "\tAge\tDailyRate\tDistanceFromHome\tEducation\tEnvironmentSatisfaction\tGender\tHourlyRate\tJobInvolvement\tJobLevel\tJobSatisfaction\t...\tJobRole_Laboratory Technician\tJobRole_Manager\tJobRole_Manufacturing Director\tJobRole_Research Director\tJobRole_Research Scientist\tJobRole_Sales Executive\tJobRole_Sales Representative\tMaritalStatus_Divorced\tMaritalStatus_Married\tMaritalStatus_Single\n",
    "655\t33\t1075\t3\t2\t4\t1\t57\t3\t1\t2\t...\t0\t0\t0\t0\t0\t0\t0\t1\t0\t0\n",
    "857\t44\t1097\t10\t4\t3\t1\t96\t3\t1\t3\t...\t0\t0\t0\t0\t1\t0\t0\t0\t0\t1\n",
    "861\t46\t1402\t2\t3\t3\t0\t69\t3\t4\t1\t...\t0\t1\t0\t0\t0\t0\t0\t0\t1\t0\n",
    "1407\t24\t771\t1\t2\t2\t1\t45\t2\t2\t3\t...\t0\t0\t0\t0\t0\t0\t0\t0\t0\t1\n",
    "744\t37\t1141\t11\t2\t1\t0\t61\t1\t2\t2\t...\t0\t0\t0\t0\t0\t0\t0\t0\t1\t0\n",
    "5 rows × 49 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb8fe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(16,8))\n",
    "\n",
    "plt.subplot(221)\n",
    "g1 = y_train.value_counts().sort_values(ascending=True).plot.bar(title= 'y_train', color=\"#1f77b4\")\n",
    "g1.set_xticklabels([\"Ex-Employee\", \"Active Employee\"])\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim(0,1100)\n",
    "for p in g1.patches:\n",
    "    height = p.get_height()\n",
    "    g1.text(p.get_x()+p.get_width()/2., height+20, \"{:1.0f}\".format(height), ha=\"center\", fontsize=14) \n",
    "    \n",
    "plt.subplot(222)\n",
    "g2 = y_test.value_counts().sort_values(ascending=True).plot.bar(title= 'y_test', color=\"#1f77b4\")\n",
    "g2.set_xticklabels([\"Ex-Employee\", \"Active Employee\"])\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim(0,400)\n",
    "for p in g2.patches:\n",
    "    height = p.get_height()\n",
    "    g2.text(p.get_x()+p.get_width()/2., height+10, \"{:1.0f}\".format(height), ha=\"center\", fontsize=14) \n",
    "    \n",
    "plt.subplot(223)\n",
    "g1 = y_train.value_counts(normalize=True).sort_values(ascending=True).plot.bar(title= 'y_train', color=\"#1f77b4\")\n",
    "g1.set_xticklabels([\"Ex-Employee\", \"Active Employee\"])\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim(0,1)\n",
    "for p in g1.patches:\n",
    "    height = p.get_height()\n",
    "    g1.text(p.get_x()+p.get_width()/2., height+0.01, \"{:1.2f}\".format(height), ha=\"center\", fontsize=14) \n",
    "    \n",
    "plt.subplot(224)\n",
    "g2 = y_test.value_counts(normalize=True).sort_values(ascending=True).plot.bar(title= 'y_test', color=\"#1f77b4\")\n",
    "g2.set_xticklabels([\"Ex-Employee\", \"Active Employee\"])\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim(0,1)\n",
    "for p in g2.patches:\n",
    "    height = p.get_height()\n",
    "    g2.text(p.get_x()+p.get_width()/2., height+0.01, \"{:1.2f}\".format(height), ha=\"center\", fontsize=14) \n",
    "\n",
    "    \n",
    "# set title and axis labels\n",
    "plt.suptitle(\"Attrition Status After Splitting\", x=0.5, y=0.95, ha=\"center\", fontsize=16)\n",
    "# fig.text(0.5, 0.001, \"Attrition\", ha=\"center\", fontsize=14)\n",
    "# fig.text(0.07, 0.5, \"No of Employee\", va=\"center\", rotation=\"vertical\", fontsize=14)\n",
    "\n",
    "# plt.savefig(\"split_hist.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ec3c0a",
   "metadata": {},
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09b4d5c",
   "metadata": {},
   "source": [
    "Feature Scaling using MinMaxScaler essentially shrinks the range such that the range is now between 0 and n. Machine Learning algorithms perform better when input numerical variables fall within a similar scale. In this case, we are scaling between 0 and 1. Refer https://stackoverflow.com/questions/50565937/how-to-normalize-the-train-and-test-data-using-minmaxscaler-sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5a0397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import MinMaxScaler from sklearn.preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# define the scaler \n",
    "scaler = MinMaxScaler(feature_range=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c5e629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the scaler on the TRAINING data and use the scaler to transform the training data\n",
    "X_train_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b898de7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the scaler to transform the TEST data\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec12868e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_scaled.shape)\n",
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476a5a04",
   "metadata": {},
   "source": [
    "(1102, 49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a9e7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "array([[0.35714286, 0.34645669, 0.        , ..., 1.        , 0.        ,\n",
    "        0.        ],\n",
    "       [0.78571429, 0.87401575, 0.10714286, ..., 0.        , 1.        ,\n",
    "        0.        ],\n",
    "       [0.80952381, 0.56406586, 0.85714286, ..., 0.        , 1.        ,\n",
    "        0.        ],\n",
    "       ...,\n",
    "       [0.52380952, 0.49319971, 0.03571429, ..., 0.        , 1.        ,\n",
    "        0.        ],\n",
    "       [0.45238095, 0.27201145, 0.07142857, ..., 0.        , 1.        ,\n",
    "        0.        ],\n",
    "       [0.4047619 , 0.40085898, 0.60714286, ..., 0.        , 1.        ,\n",
    "        0.        ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b51d9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test_scaled.shape)\n",
    "X_test_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fbf258",
   "metadata": {},
   "source": [
    "(368, 49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270517f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "array([[0.35714286, 0.69649248, 0.07142857, ..., 1.        , 0.        ,\n",
    "        0.        ],\n",
    "       [0.61904762, 0.71224052, 0.32142857, ..., 0.        , 0.        ,\n",
    "        1.        ],\n",
    "       [0.66666667, 0.9305655 , 0.03571429, ..., 0.        , 1.        ,\n",
    "        0.        ],\n",
    "       ...,\n",
    "       [0.11904762, 0.31424481, 0.03571429, ..., 1.        , 0.        ,\n",
    "        0.        ],\n",
    "       [0.30952381, 0.84037223, 0.03571429, ..., 1.        , 0.        ,\n",
    "        0.        ],\n",
    "       [0.9047619 , 0.57551897, 0.17857143, ..., 0.        , 1.        ,\n",
    "        0.        ]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963e58af",
   "metadata": {},
   "source": [
    "# Building Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503180a1",
   "metadata": {},
   "source": [
    "# Baseline Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd1f9e7",
   "metadata": {},
   "source": [
    "First, we will use a range of baseline algorithms (using default or out-of-the-box hyper-parameters) before we move on to more sophisticated solutions. Total of 9 algorithms considered in this section: Logistic Regression, Random Forest, SVM, KNN, Decision Tree Classifier, Gaussian NB, XGBoost, Gradient Boosting, AdaBoost. Then, we will pick the top 2-3 algorithms and further fine-tune their parameter values using GridSearchCV to achieve the best AUC score.\n",
    "\n",
    "We will evaluate the algorithms based on two metrics:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dd201f",
   "metadata": {},
   "source": [
    "Classification Accuracy is the number of correct predictions made as a ratio of all predictions made.\n",
    "It is the most common evaluation metric for classification problems. However, it is often misused as it is only really suitable when there are an equal number of observations in each class and all predictions and prediction errors are equally important. It is not the case in this project, so a different scoring metric may be more suitable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c33411f",
   "metadata": {},
   "source": [
    "Area under ROC Curve (or AUC for short) is a performance metric for binary classification problems.\n",
    "The AUC represents a model’s ability to discriminate between positive and negative classes. An area of 1.0 represents a model that made all predictions perfectly. An area of 0.5 represents a model as good as random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b1f3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n",
    "\n",
    "# sklearn modules for ML model selection\n",
    "from sklearn.model_selection import train_test_split  # import 'train_test_split'\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Libraries for data modelling\n",
    "from sklearn import svm, tree, linear_model, neighbors\n",
    "from sklearn import naive_bayes, ensemble, discriminant_analysis, gaussian_process\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# sklearn modules for performance metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_curve\n",
    "from sklearn.metrics import auc, roc_auc_score, roc_curve, recall_score, log_loss\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score, make_scorer\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3095fb4b",
   "metadata": {},
   "source": [
    "0.19.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831e96a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selection of algorithms to consider and set performance measure\n",
    "models = []\n",
    "models.append((\"Logistic Regression\", LogisticRegression(solver=\"liblinear\", random_state=0)))\n",
    "models.append((\"Random Forest\", RandomForestClassifier(n_estimators=100, random_state=0)))\n",
    "models.append((\"SVM\", SVC(gamma=\"auto\", random_state=0)))\n",
    "models.append((\"KNN\", KNeighborsClassifier()))\n",
    "models.append((\"Decision Tree Classifier\", DecisionTreeClassifier(random_state=0)))\n",
    "models.append((\"Gaussian NB\", GaussianNB()))\n",
    "models.append((\"XGBoost\", XGBClassifier(random_state=0)))\n",
    "models.append((\"Gradient Boosting\", GradientBoostingClassifier(random_state=0)))\n",
    "models.append((\"AdaBoost\", AdaBoostClassifier(random_state=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9921beee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# evaluate each model in turn and provide accuracy and standard deviation scores\n",
    "\n",
    "acc_results = []\n",
    "auc_results = []\n",
    "names = []\n",
    "\n",
    "# set table to table to populate with performance results\n",
    "col = [\"Algorithm\", \"ROC AUC Mean\", \"ROC AUC STD\", \"Accuracy Mean\", \"Accuracy STD\"]\n",
    "df_results = pd.DataFrame(columns=col)\n",
    "i = 0\n",
    "\n",
    "# evaluate each model using cross-validation\n",
    "for name, model in models:\n",
    "    # 10-fold cross-validation\n",
    "    kfold = KFold(n_splits=10, random_state=0)  \n",
    "\n",
    "    # accuracy scoring\n",
    "    cv_acc_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=\"accuracy\")\n",
    "\n",
    "    # roc_auc scoring\n",
    "    cv_auc_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=\"roc_auc\")\n",
    "\n",
    "    acc_results.append(cv_acc_results)\n",
    "    auc_results.append(cv_auc_results)\n",
    "    names.append(name)\n",
    "    df_results.loc[i] = [name,\n",
    "                         round(cv_auc_results.mean()*100, 2),\n",
    "                         round(cv_auc_results.std()*100, 2),\n",
    "                         round(cv_acc_results.mean()*100, 2),\n",
    "                         round(cv_acc_results.std()*100, 2)\n",
    "                         ]\n",
    "    i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9662e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wall time: 33.5 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992595a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the results by Accuracy\n",
    "df_results.sort_values(by=[\"Accuracy Mean\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aab479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Algorithm\tROC AUC Mean\tROC AUC STD\tAccuracy Mean\tAccuracy STD\n",
    "0\tLogistic Regression\t81.41\t6.06\t87.30\t2.85\n",
    "6\tXGBoost\t79.92\t7.69\t87.12\t2.19\n",
    "8\tAdaBoost\t80.43\t9.26\t86.48\t2.19\n",
    "1\tRandom Forest\t79.10\t5.65\t85.85\t4.26\n",
    "7\tGradient Boosting\t79.12\t8.05\t85.67\t2.57\n",
    "2\tSVM\t50.00\t0.00\t83.85\t4.05\n",
    "3\tKNN\t55.58\t9.66\t81.41\t4.04\n",
    "4\tDecision Tree Classifier\t58.03\t8.14\t78.41\t2.55\n",
    "5\tGaussian NB\t76.07\t7.65\t77.85\t5.71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e47c016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the results by ROC AUC\n",
    "df_results.sort_values(by=[\"ROC AUC Mean\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728a8328",
   "metadata": {},
   "outputs": [],
   "source": [
    "Algorithm\tROC AUC Mean\tROC AUC STD\tAccuracy Mean\tAccuracy STD\n",
    "0\tLogistic Regression\t81.41\t6.06\t87.30\t2.85\n",
    "8\tAdaBoost\t80.43\t9.26\t86.48\t2.19\n",
    "6\tXGBoost\t79.92\t7.69\t87.12\t2.19\n",
    "7\tGradient Boosting\t79.12\t8.05\t85.67\t2.57\n",
    "1\tRandom Forest\t79.10\t5.65\t85.85\t4.26\n",
    "5\tGaussian NB\t76.07\t7.65\t77.85\t5.71\n",
    "4\tDecision Tree Classifier\t58.03\t8.14\t78.41\t2.55\n",
    "3\tKNN\t55.58\t9.66\t81.41\t4.04\n",
    "2\tSVM\t50.00\t0.00\t83.85\t4.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfdf263",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 8))\n",
    "\n",
    "ax1 = fig.add_subplot(211)\n",
    "plt.boxplot(acc_results)\n",
    "ax1.set_xticklabels(names)\n",
    "plt.title(\"Accuracy Comparison\")\n",
    "\n",
    "fig.subplots_adjust(hspace=0.4)\n",
    "\n",
    "ax2 = fig.add_subplot(212)\n",
    "plt.boxplot(auc_results)\n",
    "ax2.set_xticklabels(names)\n",
    "plt.title(\"ROC AUC Comparison\")\n",
    "\n",
    "# plt.savefig(\"boxplots.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9f2318",
   "metadata": {},
   "source": [
    "Based on our Accuracy and ROC AUC comparison analysis, Logistic Regression and XGBoost have the highest mean Accuracy score while Logistic Regression also has the highest mean AUC scores. We will shortlist these two algorithms together with Random Forest for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96557c87",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4d9854",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=10, random_state=0)\n",
    "modelCV = LogisticRegression(solver='liblinear', random_state=0)\n",
    "scoring = 'roc_auc'\n",
    "results = cross_val_score(modelCV, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "print(results, \"\\n\")\n",
    "print(\"Average AUC score = {:1.4f}; standard deviation = {:1.4f}\".format(results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "391ab29f",
   "metadata": {},
   "source": [
    "[0.86208791 0.79001976 0.83914729 0.68982456 0.86088818 0.8164794\n",
    " 0.84002976 0.85403509 0.71507151 0.87367021] \n",
    "\n",
    "Average AUC score = 0.8141; standard deviation = 0.0606"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc0f5fc",
   "metadata": {},
   "source": [
    "# Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce930f7e",
   "metadata": {},
   "source": [
    "GridSearchCV allows us to fine-tune hyper-parameters by searching over specified parameter values for an estimator. The results from GridSearchCV provided us with fine-tuned hyper-parameter using ROC_AUC as the scoring metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a454a47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "param_grid = {\"C\": np.arange(1e-01, 1.01, 0.1), \"class_weight\": [\"balanced\", None]} # hyper-parameter list to fine-tune\n",
    "\n",
    "log_gs = GridSearchCV(LogisticRegression(solver=\"liblinear\", \n",
    "                                         random_state=0),\n",
    "                                         iid=True,\n",
    "                                         return_train_score=True,\n",
    "                                         param_grid=param_grid,\n",
    "                                         scoring=\"roc_auc\",\n",
    "                                         cv=10)\n",
    "\n",
    "log_gs.fit(X_train, y_train)\n",
    "\n",
    "print(\"=\"*20)\n",
    "print(\"best estimator: \" + str(log_gs.best_estimator_))\n",
    "print(\"best params: \" + str(log_gs.best_params_))\n",
    "print(\"best score:\", log_gs.best_score_)\n",
    "print(\"=\"*20)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "edfbf85c",
   "metadata": {},
   "source": [
    "best estimator: LogisticRegression(C=0.8, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
    "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
    "          verbose=0, warm_start=False)\n",
    "best params: {'C': 0.8, 'class_weight': None}\n",
    "best score: 0.8225763528901684\n",
    "====================\n",
    "Wall time: 8.47 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906106ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "y_pred = log_gs.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5429a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate accuracy score\n",
    "logit_accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy of Logistic Regression Classifier on Test set: {:.2f}%'.format(logit_accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f41bf5",
   "metadata": {},
   "source": [
    "Accuracy of Logistic Regression Classifier on Test set: 87.50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887037d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the code to view the classification report metrics\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8364d1bd",
   "metadata": {},
   "source": [
    "precision    recall  f1-score   support\n",
    "\n",
    "          0       0.88      0.99      0.93       309\n",
    "          1       0.84      0.27      0.41        59\n",
    "\n",
    "avg / total       0.87      0.88      0.85       368"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8bf2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate AUC score using test dataset\n",
    "# we will only keep probabilities associated with the employee leaving\n",
    "y_pred_prob = log_gs.predict_proba(X_test)[:, 1]\n",
    "logit_roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "print(\"AUC on Test set: {}\".format(logit_roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d80c17",
   "metadata": {},
   "source": [
    "AUC on Test set: 0.8144917996818606"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148e928d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    " \n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.xaxis.set_label_position(\"top\")\n",
    "\n",
    "# f, ax = plt.subplots(figsize=(9, 6))\n",
    "sns.heatmap(cm, annot=True, annot_kws={\"size\":16}, fmt=\"d\", cbar=False, linewidths=0.1, cmap=\"Blues\")\n",
    "plt.title('Confusion matrix of the classifier', fontsize=14)\n",
    "plt.ylabel('Actual label', fontsize=12)\n",
    "plt.xlabel('Predicted label', fontsize=12)\n",
    "\n",
    "# plt.savefig(\"log_cm.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef873552",
   "metadata": {},
   "source": [
    "# XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb720f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=10, random_state=0)\n",
    "modelCV = XGBClassifier(random_state=0)\n",
    "scoring = 'roc_auc'\n",
    "results = cross_val_score(modelCV, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "print(results, \"\\n\")\n",
    "print(\"Average AUC score = {:1.4f}; standard deviation = {:1.4f}\".format(results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6261d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "[0.86923077 0.82460474 0.80281008 0.71929825 0.90636704 0.81754949\n",
    " 0.83333333 0.72140351 0.64136414 0.85638298] \n",
    "\n",
    "Average AUC score = 0.7992; standard deviation = 0.0769"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519bf679",
   "metadata": {},
   "source": [
    "# Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a0fbc3",
   "metadata": {},
   "source": [
    "GridSearchCV allows use to fine-tune hyper-parameters by searching over specified parameter values for an estimator. The results from GridSearchCV provided us with fine-tuned hyper-parameter using ROC_AUC as the scoring metric. The default parameter values for XGBClassifier are n_estimators=100, max_depth=3, learning_rate=0.1, gamma=0.\n",
    "Refer https://xgboost.readthedocs.io/en/latest/python/python_api.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d49d158",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xgb_classifier = XGBClassifier(random_state=0)\n",
    "\n",
    "param_grid = {\"n_estimators\": [100, 150, 200],\n",
    "              \"max_depth\": [2, 3, 4],\n",
    "              \"learning_rate\":[0.01, 0.1],\n",
    "              \"gamma\": [1,2,3]}\n",
    "\n",
    "xgb_clf = GridSearchCV(xgb_classifier,\n",
    "                        param_grid=param_grid,\n",
    "                        scoring=\"roc_auc\",\n",
    "                        cv=10)\n",
    "\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"=\"*20)\n",
    "print(\"best estimator: \" + str(xgb_clf.best_estimator_))\n",
    "print(\"best params: \" + str(xgb_clf.best_params_))\n",
    "print(\"best score:\", xgb_clf.best_score_)\n",
    "print(\"=\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6352e348",
   "metadata": {},
   "outputs": [],
   "source": [
    "best estimator: XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=1, gamma=2, learning_rate=0.1, max_delta_step=0,\n",
    "       max_depth=2, min_child_weight=1, missing=None, n_estimators=150,\n",
    "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=1)\n",
    "best params: {'gamma': 2, 'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 150}\n",
    "best score: 0.8196073552657408\n",
    "====================\n",
    "Wall time: 1min 51s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c26c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature importances\n",
    "importances = xgb_clf.best_estimator_.feature_importances_\n",
    "df_param_coeff = pd.DataFrame(columns=['Feature', 'Coefficient'])\n",
    "for i in range(len(X_train.columns)):\n",
    "    feat = X_train.columns[i]\n",
    "    coeff = importances[i]\n",
    "    df_param_coeff.loc[i] = (feat, coeff)\n",
    "df_param_coeff.sort_values(by='Coefficient', ascending=False, inplace=True)\n",
    "df_param_coeff = df_param_coeff.reset_index(drop=True)\n",
    "df_param_coeff.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635749e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature\tCoefficient\n",
    "0\tMonthlyIncome\t0.0750\n",
    "1\tStockOptionLevel\t0.0700\n",
    "2\tOverTime\t0.0700\n",
    "3\tDailyRate\t0.0500\n",
    "4\tDistanceFromHome\t0.0500\n",
    "5\tNumCompaniesWorked\t0.0500\n",
    "6\tJobSatisfaction\t0.0450\n",
    "7\tTrainingTimesLastYear\t0.0450\n",
    "8\tYearsAtCompany\t0.0425\n",
    "9\tJobInvolvement\t0.0375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f94526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot feature importances\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.title(\"Feature Importances\", fontsize=16)\n",
    "plt.xlim(0,0.11)\n",
    "feat_importances = pd.Series(xgb_clf.best_estimator_.feature_importances_, index=X_train.columns)\n",
    "g1 = feat_importances.sort_values().plot(kind=\"barh\", color=\"#1f77b4\")\n",
    "for i in g1.patches:\n",
    "    # get_width pulls left or right; get_y pushes up or down\n",
    "    g1.text(i.get_width()+.001, i.get_y()+.0, \"{:1.4f}\".format(i.get_width()), fontsize=12)\n",
    "    \n",
    "# plt.savefig(\"xgb_f.png\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5807ea62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "y_pred = xgb_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14266334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate accuracy score\n",
    "xgb_accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy of XGBoost Classifier on test set: {:.2f}%'.format(xgb_accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9619b48e",
   "metadata": {},
   "source": [
    "Accuracy of XGBoost Classifier on test set: 88.04%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934ce72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the code to view the classification report metrics\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "59e22d26",
   "metadata": {},
   "source": [
    "precision    recall  f1-score   support\n",
    "\n",
    "          0       0.88      0.99      0.93       309\n",
    "          1       0.86      0.31      0.45        59\n",
    "\n",
    "avg / total       0.88      0.88      0.86       368"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2517a316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate AUC score using test dataset\n",
    "# we will only keep probabilities associated with the employee leaving\n",
    "y_pred_prob = xgb_clf.predict_proba(X_test)[:, 1]\n",
    "xgb_roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "print(\"AUC on test set: {}\".format(xgb_roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aa452d",
   "metadata": {},
   "source": [
    "AUC on test set: 0.821896769239208"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b7c198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    " \n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.xaxis.set_label_position(\"top\")\n",
    "\n",
    "# f, ax = plt.subplots(figsize=(9, 6))\n",
    "sns.heatmap(cm, annot=True, annot_kws={\"size\":16}, fmt=\"d\", cbar=False, linewidths=0.1, cmap=\"Blues\")\n",
    "plt.title('Confusion matrix of XGBoost classifier', fontsize=14)\n",
    "plt.ylabel('Actual label', fontsize=12)\n",
    "plt.xlabel('Predicted label', fontsize=12)\n",
    "\n",
    "# plt.savefig(\"scatterplots.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936f2410",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645e8629",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=10, random_state=0)\n",
    "modelCV = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "scoring = 'roc_auc'\n",
    "results = cross_val_score(modelCV, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "print(results, \"\\n\")\n",
    "print(\"Average AUC score = {:1.4f}; standard deviation = {:1.4f}\".format(results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6698faaa",
   "metadata": {},
   "source": [
    "[0.87115385 0.7902668  0.76114341 0.67122807 0.86088818 0.82664526\n",
    " 0.82552083 0.79157895 0.74147415 0.76961436] \n",
    "\n",
    "Average AUC score = 0.7910; standard deviation = 0.0565"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268b253b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rf_classifier = RandomForestClassifier(random_state=0)\n",
    "\n",
    "param_grid = {\"n_estimators\": [150, 200, 250],\n",
    "              \"min_samples_split\":[2,4,6],\n",
    "              \"min_samples_leaf\": [1, 2],\n",
    "#               \"max_depth\": [5, 10, 15, 20, 25],\n",
    "              \"class_weight\": [\"balanced\", None]}\n",
    "\n",
    "grid_obj = GridSearchCV(rf_classifier,\n",
    "                        param_grid=param_grid,\n",
    "                        scoring=\"roc_auc\",\n",
    "                        cv=10)\n",
    "\n",
    "grid_fit = grid_obj.fit(X_train, y_train)\n",
    "rf_opt = grid_fit.best_estimator_\n",
    "\n",
    "print(\"=\"*20)\n",
    "print(\"best estimator: \" + str(grid_obj.best_estimator_))\n",
    "print(\"best params: \" + str(grid_obj.best_params_))\n",
    "print(\"best score:\", grid_obj.best_score_)\n",
    "print(\"=\"*20)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "705757f1",
   "metadata": {},
   "source": [
    "best estimator: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=4,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=1,\n",
    "            oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "best params: {'class_weight': None, 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 200}\n",
    "best score: 0.8133575652002222\n",
    "====================\n",
    "Wall time: 2min 48s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cd0a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature importances\n",
    "importances = grid_obj.best_estimator_.feature_importances_\n",
    "df_param_coeff = pd.DataFrame(columns=['Feature', 'Coefficient'])\n",
    "for i in range(len(X_train.columns)):\n",
    "    feat = X_train.columns[i]\n",
    "    coeff = importances[i]\n",
    "    df_param_coeff.loc[i] = (feat, coeff)\n",
    "df_param_coeff.sort_values(by='Coefficient', ascending=False, inplace=True)\n",
    "df_param_coeff = df_param_coeff.reset_index(drop=True)\n",
    "df_param_coeff.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f79aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature\tCoefficient\n",
    "0\tMonthlyIncome\t0.080944\n",
    "1\tAge\t0.060090\n",
    "2\tOverTime\t0.058972\n",
    "3\tDailyRate\t0.054846\n",
    "4\tTotalWorkingYears\t0.048805\n",
    "5\tMonthlyRate\t0.046522\n",
    "6\tDistanceFromHome\t0.044237\n",
    "7\tHourlyRate\t0.042248\n",
    "8\tYearsAtCompany\t0.040938\n",
    "9\tNumCompaniesWorked\t0.032822"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b769798d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot feature importances\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.title(\"Feature Importances\", fontsize=16)\n",
    "plt.xlim(0,0.09)\n",
    "feat_importances = pd.Series(grid_obj.best_estimator_.feature_importances_, index=X_train.columns)\n",
    "g1 = feat_importances.sort_values().plot(kind=\"barh\", color=\"#1f77b4\")\n",
    "for i in g1.patches:\n",
    "    # get_width pulls left or right; get_y pushes up or down\n",
    "    g1.text(i.get_width()+.001, i.get_y()+.0, \"{:1.4f}\".format(i.get_width()), fontsize=12)\n",
    "    \n",
    "# plt.savefig(\"rf_f.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de741bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "y_pred = grid_obj.predict(X_test)\n",
    "# calculate accuracy score\n",
    "rf_accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy of Random Forest Classifier on Test set: {:.2f}%'.format(rf_accuracy*100))\n",
    "Accuracy of Random Forest Classifier on Test set: 85.33%\n",
    "# Run the code to view the classification report metrics\n",
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "          0       0.85      1.00      0.92       309\n",
    "          1       0.86      0.10      0.18        59\n",
    "\n",
    "avg / total       0.85      0.85      0.80       368\n",
    "\n",
    "# calculate AUC score using test dataset\n",
    "# we will only keep probabilities associated with the employee leaving\n",
    "y_pred_prob = grid_obj.predict_proba(X_test)[:, 1]\n",
    "rf_roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "print(\"AUC on Test set: {}\".format(rf_roc_auc))\n",
    "AUC on Test set: 0.8028084032691569\n",
    "# import confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    " \n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.xaxis.set_label_position(\"top\")\n",
    "\n",
    "# f, ax = plt.subplots(figsize=(9, 6))\n",
    "sns.heatmap(cm, annot=True, annot_kws={\"size\":16}, fmt=\"d\", cbar=False, linewidths=0.1, cmap=\"Blues\")\n",
    "plt.title('Confusion matrix of Random Forest classifier', fontsize=14)\n",
    "plt.ylabel('Actual label', fontsize=12)\n",
    "plt.xlabel('Predicted label', fontsize=12)\n",
    "\n",
    "# plt.savefig(\"rf_cm.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c693fe3",
   "metadata": {},
   "source": [
    "The Confusion matrix is telling us that we have 308+6 correct predictions and 53+1 incorrect predictions. In other words, an accurac of 85.33%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a00689",
   "metadata": {},
   "source": [
    "# ROC Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f6f08a",
   "metadata": {},
   "source": [
    "AUC - ROC curve is a performance measurement for classification problem at various thresholds settings. ROC is a probability curve and AUC represents degree or measure of separability. It tells how much a model is capable of distinguishing between classes. The dotted line represents the ROC curve of a purely random classifier; a good classifier stays as far away from that line as possible (toward the top-left corner)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5c9b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ROC curves\n",
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, log_gs.predict_proba(X_test)[:,1])\n",
    "xgb_fpr, xgb_tpr, xgb_thresholds = roc_curve(y_test, xgb_clf.predict_proba(X_test)[:,1])\n",
    "rf_fpr, rf_tpr, rf_thresholds = roc_curve(y_test, grid_obj.predict_proba(X_test)[:,1])\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# plot XGBoost ROC\n",
    "plt.plot(xgb_fpr, xgb_tpr, label=\"XGBoost (AUC = {:1.4f})\".format(xgb_roc_auc))\n",
    "# plot Logistic Regression ROC\n",
    "plt.plot(fpr, tpr, label=\"Logistic Regression (AUC = {:1.4f})\".format(logit_roc_auc))\n",
    "# plot Random Forest ROC\n",
    "plt.plot(rf_fpr, rf_tpr, label=\"Random Forest (AUC = {:1.4f})\".format(rf_roc_auc))\n",
    "# plot Baseline ROC\n",
    "plt.plot([0,1], [0,1],label=\"Baseline (AUC = 0.5000)\", linestyle=\"--\")\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\", fontsize=14)\n",
    "plt.ylabel(\"True Positive Rate\", fontsize=14)\n",
    "plt.title(\"ROC Curve\", fontsize=16)\n",
    "plt.legend(loc=\"lower right\")\n",
    "# plt.savefig(\"roc.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e46efc7",
   "metadata": {},
   "source": [
    "As shown above, the fine-tuned XGBoost model showed a higher AUC score compared to Logistic Regression and Random Forest Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6e7021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all models' results into one dataframe\n",
    "data = {\"Model\": [\"XGBoost\", \"Logistic Regression\", \"Random Forest\"], \n",
    "        \"Accuracy\": [xgb_accuracy, logit_accuracy, rf_accuracy]}\n",
    "\n",
    "results = pd.DataFrame(data=data)\n",
    "results\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.title(\"Accuracy on Test Set\", fontsize=16)\n",
    "g1 = sns.barplot(x=\"Model\", y=\"Accuracy\", data=results)\n",
    "plt.ylim(0, 1)\n",
    "g1.set_xlabel(\"\")\n",
    "g1.tick_params(labelsize=14)\n",
    "for p in g1.patches:\n",
    "    height = p.get_height()\n",
    "    g1.text(p.get_x()+p.get_width()/2., height+0.01, \"{:1.4f}\".format(height), ha=\"center\", fontsize=14) \n",
    "    \n",
    "# plt.savefig(\"acc_results.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69ecac0",
   "metadata": {},
   "source": [
    "# Discussion and Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff7eb68",
   "metadata": {},
   "source": [
    "Comparing the 9 different algorithms with default parameter values (before fine-tuning), Logistic Regression has the best accuracy score (0.8730) and the best ROC AUC (0.8141). After fine-tuning the parameter values, XGBoost performed the best with the highest accuracy (0.8804) and ROC AUC (0.8219) on Test set. It is not surprising that XGBoost is an algorithm that has recently been dominating Kaggle competitions. According to the author of XGBoost, both XGBoost and GBM follows the principle of gradient boosting. There are however, the difference in modeling details. Specifically, xgboost used a more regularized model formalization to control over-fitting, which gives it better performance. The name xgboost, though, actually refers to the engineering goal to push the limit of computations resources for boosted tree algorithms. Which is the reason why many people use xgboost. For model, it might be more suitable to be called as regularized gradient boosting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e30980",
   "metadata": {},
   "source": [
    "# Risk Category, Indicators and Strategic Retention Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9a1bbd",
   "metadata": {},
   "source": [
    "Risk Category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13512a15",
   "metadata": {},
   "source": [
    "As the company generates more data on its employees (on New Joiners and recent Leavers) the algorithm can be re-trained using the additional data and theoritically generate more accurate predictions to identify high-risk employees of leaving based on the probabilistic label assigned to each feature variable (i.e. employee) by the algorithm.\n",
    "\n",
    "Employees can be assigning a \"Risk Category\" based on the predicted probability of leaving the company:\n",
    "\n",
    "Low-risk for employees with probability < 0.6\n",
    "Medium-risk for employees with probability between 0.6 and 0.8\n",
    "High-risk for employees with probability > 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957ef140",
   "metadata": {},
   "source": [
    "# Strategic Retention Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e7871e",
   "metadata": {},
   "source": [
    "# The stronger indicators of people leaving include:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12e7b0d",
   "metadata": {},
   "source": [
    "Monthly Income: people on higher wages are less likely to leave the company. Hence, efforts should be made to gather information on industry benchmarks in the current local market to determine if the company is providing competitive wages.\n",
    "Over Time: people who work overtime are more likely to leave the company. Hence efforts must be taken to appropriately scope projects upfront with adequate support and manpower so as to reduce the use of overtime.\n",
    "Age: Employees in relatively young age bracket 25–35 are more likely to leave. Hence, efforts should be made to clearly articulate the long-term vision of the company and young employees fit in that vision, as well as provide incentives in the form of clear paths to promotion for instance.\n",
    "DistanceFromHome: Employees who live further from home are more likely to leave the company. Hence, efforts should be made to provide support in the form of company transportation for clusters of employees leaving the same area, or in the form of Transportation Allowance. Initial screening of employees based on their home location is probably not recommended as it would be regarded as a form of discrimination as long as employees make it to work on time every day.\n",
    "TotalWorkingYears: The more experienced employees are less likely to leave. Employees who have between 5–8 years of experience should be identified as potentially having a higher-risk of leaving.\n",
    "YearsAtCompany: Loyal companies are less likely to leave. Employees who hit their two-year anniversary should be identified as potentially having a higher-risk of leaving.\n",
    "YearsWithCurrManager: A large number of leavers leave 6 months after their Current Managers. By using Line Manager details for each employee, one can determine which Manager have experienced the largest numbers of employees resigning over the past year.\n",
    "WorkLifeBalance: Employees who had \"Bad\" Work-Life Balance are more likely to leave the company. Hence, efforts should be made to improve the work life balance of the employees such as limiting the hours of overtime, flexible working hours, option of working from home, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b36be7",
   "metadata": {},
   "source": [
    "Several metrics can be used here to determine whether action should be taken with a Line Manager:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffd1e2f",
   "metadata": {},
   "source": [
    "number of years the Line Manager has been in a particular position: this may indicate that the employees may need management training or be assigned a mentor (ideally an Executive) in the organisation\n",
    "Patterns in the employees who have resigned: this may indicate recurring patterns in employees leaving in which case action may be taken accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaff6ac9",
   "metadata": {},
   "source": [
    "A strategic \"Retention Plan\" should be drawn for each Risk Category group. In addition to the suggested steps for each feature listed above, face-to-face meetings between a HR representative and employees can be initiated for medium- and high-risk employees to discuss work conditions. Also, a meeting with those employee's Line Manager would allow to discuss the work environment within the team and whether steps can be taken to improve it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87e4a68",
   "metadata": {},
   "source": [
    "If you have any feedback for this project, feel free to contact me via my LinkedIn or GitHub Pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535002f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
